{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "# --------------------------------------------------------\n",
    "# References:\n",
    "# DeiT: https://github.com/facebookresearch/deit\n",
    "# BEiT: https://github.com/microsoft/unilm/tree/master/beit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "# assert timm.__version__ == \"0.3.2\" # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_vit\n",
    "\n",
    "from engine_finetune import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('MAE fine-tuning for image segmentation', add_help=False)\n",
    "    parser.add_argument('--batch_size', default=64, type=int,\n",
    "                        help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')\n",
    "    parser.add_argument('--epochs', default=300, type=int)\n",
    "    parser.add_argument('--accum_iter', default=1, type=int,\n",
    "                        help='Accumulate gradient iterations (for increasing the effective batch size under memory constraints)')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--encoder_model', default='mae_vit_medical_base_patch16', type=str, metavar='MODEL',\n",
    "                        help='Name of encoder pretrained')\n",
    "\n",
    "    parser.add_argument('--model',default='mae_vit3d_medical_base_windowsize4',type=str,\n",
    "                        help='Name of model to train')\n",
    "\n",
    "    parser.add_argument('--input_size', default=224, type=int,\n",
    "                        help='images input size')\n",
    "\n",
    "    parser.add_argument('--drop_path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    \n",
    "\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--clip_grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.0005,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, metavar='LR',\n",
    "                        help='learning rate (absolute lr)')\n",
    "    parser.add_argument('--blr', type=float, default=1e-4, metavar='LR',\n",
    "                        help='base learning rate: absolute_lr = base_lr * total_batch_size / 256')\n",
    "    parser.add_argument('--layer_decay', type=float, default=0.5,\n",
    "                        help='layer-wise lr decay from ELECTRA/BEiT')\n",
    "\n",
    "    parser.add_argument('--min_lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0')\n",
    "\n",
    "    parser.add_argument('--warmup_epochs', type=int, default=5, metavar='N',\n",
    "                        help='epochs to warmup LR')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color_jitter', type=float, default=None, metavar='PCT',\n",
    "                        help='Color jitter factor (enabled only when not using Auto/RandAug)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1,\n",
    "                        help='Label smoothing (default: 0.1)')\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0,\n",
    "                        help='mixup alpha, mixup enabled if > 0.')\n",
    "    parser.add_argument('--cutmix', type=float, default=0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0.')\n",
    "    parser.add_argument('--cutmix_minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup_prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup_switch_prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup_mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', default='/data/zhanghao/skull_project/mae-main/mae_medical_base_pretrain/checkpoint-399.pth',\n",
    "                        help='finetune from checkpoint')\n",
    "    parser.add_argument('--global_pool', action='store_true')\n",
    "    parser.set_defaults(global_pool=True)\n",
    "    parser.add_argument('--cls_token', action='store_false', dest='global_pool',\n",
    "                        help='Use class token instead of global pool for classification')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data_path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--nb_classes', default=1000, type=int,\n",
    "                        help='number of the classification types')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='./my_ViT_finetune_seg_base_3d',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--log_dir', default='./my_ViT_finetune_seg_base_3d',\n",
    "                        help='path where to tensorboard log')\n",
    "    parser.add_argument('--device', default='cuda:0',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='',\n",
    "                        help='resume from checkpoint')\n",
    "\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true',\n",
    "                        help='Perform evaluation only')\n",
    "    parser.add_argument('--dist_eval', action='store_true', default=False,\n",
    "                        help='Enabling distributed evaluation (recommended during training for faster monitor')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--local_rank', default=-1, type=int)\n",
    "    parser.add_argument('--dist_on_itp', action='store_true')\n",
    "    parser.add_argument('--dist_url', default='env://',\n",
    "                        help='url used to set up distributed training')\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 43, 42)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.ccdataset3d import *\n",
    "train_paths, valid_paths, test_paths = getPathList()\n",
    "train_loader, valid_loader, test_loader = getDataloader(\n",
    "    train_paths, valid_paths, test_paths)\n",
    "len(train_loader),len(valid_loader),len(test_loader)\n",
    "# torch.Size([64, 1, 224, 224]) torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 冻结encoder权重进行下游任务训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n"
     ]
    }
   ],
   "source": [
    "from ast import arg\n",
    "import my_seg_vit\n",
    "import util.lr_sched as lr_sched\n",
    "import math\n",
    "import sys\n",
    "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
    "import seg3d_2dencoder \n",
    "import maeseg2d3d \n",
    "def main(args):\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + misc.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed) \n",
    "\n",
    "    cudnn.benchmark = True  \n",
    "    \n",
    "    #load encoder\n",
    "    encoder = seg3d_2dencoder.__dict__[args.encoder_model](lossforpatch = False)\n",
    "\n",
    "    #load dict\n",
    "    checkpoiont = torch.load(args.finetune,map_location='cpu')\n",
    "    print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "    checkpoint_model = checkpoiont['model']\n",
    "\n",
    "    state_dict = encoder.state_dict()\n",
    "    for k in ['head.weight', 'head.bias']:\n",
    "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "    # interpolate position embedding\n",
    "    interpolate_pos_embed(encoder, checkpoint_model)\n",
    "\n",
    "    # load pre-trained model\n",
    "    msg = encoder.load_state_dict(checkpoint_model, strict=False)\n",
    "    # print(msg)\n",
    "    # encoder.to(device)\n",
    "    # Freezes Encoder weights\n",
    "    for name, para in encoder.named_parameters():\n",
    "        para.requires_grad_(False)\n",
    "        \n",
    "    model = maeseg2d3d.__dict__[args.model](encoder=encoder)\n",
    "    model.to(device)\n",
    "    \n",
    "    model_without_ddp = model\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    print(\"Model = %s\" % str(model_without_ddp))\n",
    "    print('number of params (M): %.2f' % (n_parameters / 1.e6))\n",
    "\n",
    "    eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "\n",
    "    print(\"actual lr: %.2e\" % args.lr)\n",
    "\n",
    "    print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "    print(\"effective batch size: %d\" % eff_batch_size)\n",
    "\n",
    "    #加了layer_decay\n",
    "    param_groups = lrd.param_groups_lrd(model_without_ddp, args.weight_decay,\n",
    "        layer_decay=args.layer_decay\n",
    "    )\n",
    "    # param_groups = optim_factory.param_groups_weight_decay(\n",
    "    #     model_without_ddp, args.weight_decay)\n",
    " \n",
    "    optimizer = torch.optim.AdamW(param_groups, lr=args.lr)\n",
    "    print(\"查看optimizer = \",optimizer)\n",
    "    loss_scaler = NativeScaler() \n",
    "\n",
    "\n",
    "    misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)\n",
    "\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    dice_list = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        #----------------------------训练---------------------------------------------\n",
    "        model.train()\n",
    "        metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "        metric_logger.add_meter('lr', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "        accum_iter = args.accum_iter\n",
    "        optimizer.zero_grad()#优化器清零\n",
    "        if log_writer is not None:\n",
    "            print('log_dir: {}'.format(log_writer.log_dir))\n",
    "\n",
    "        for data_iter_step,data in enumerate(train_loader):\n",
    "            if data_iter_step % accum_iter == 0:\n",
    "                lr_sched.adjust_learning_rate(optimizer, data_iter_step / len(train_loader) + epoch, args)\n",
    "            samples = data[\"image\"]  # 我自己的数据是data[\"image\"]表示图片\n",
    "            labeles = data[\"mask\"]\n",
    "            # print(\"mask.shape = \",labeles.shape)\n",
    "            # print(\"samples.shape = \",samples.shape)\n",
    "            # print(\"mask.type = \",labeles.dtype)\n",
    "            samples = samples.to(device, non_blocking=True)\n",
    "            labeles = labeles.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                loss, _,  = model(samples, labeles)\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "            if not math.isfinite(loss_value):\n",
    "                print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "                sys.exit(1)\n",
    "\n",
    "            loss /= accum_iter\n",
    "            loss_scaler(loss, optimizer, parameters=model.parameters(),update_grad=(data_iter_step + 1) % accum_iter == 0)\n",
    "\n",
    "            if (data_iter_step + 1) % accum_iter == 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            metric_logger.update(loss=loss_value)\n",
    "\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            metric_logger.update(lr=lr)\n",
    "\n",
    "            loss_value_reduce = misc.all_reduce_mean(loss_value)\n",
    "\n",
    "            if log_writer is not None :\n",
    "                \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "                This calibrates different curves when batch size changes.\n",
    "                \"\"\"\n",
    "                epoch_1000x = int(\n",
    "                    (data_iter_step / len(train_loader) + epoch) * 1000)\n",
    "                log_writer.add_scalar('train_loss', loss_value_reduce, epoch_1000x)\n",
    "                log_writer.add_scalar('lr', lr, epoch_1000x)\n",
    "\n",
    "        # gather the stats from all processes\n",
    "        metric_logger.synchronize_between_processes()\n",
    "        print(\"Averaged stats:\", metric_logger)\n",
    "        train_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n",
    "        #----------------------------验证-----------------------------------------------\n",
    "        #每4个epoch进行一次验证\n",
    "        if(epoch%4==0):\n",
    "            with torch.no_grad(): #表示在验证的时候不需要梯度计算\n",
    "                model.eval()\n",
    "                dice_score = 0.\n",
    "                iou_score = 0.\n",
    "                for data in valid_loader:\n",
    "                    valid_image = data[\"image\"]\n",
    "                    valid_target = data[\"mask\"]\n",
    "\n",
    "                    valid_image = valid_image.to(device, non_blocking=True)\n",
    "                    valid_target = valid_target.to(device, non_blocking=True)\n",
    "\n",
    "                    _,out = model(valid_image, valid_target) #[N,196,256]\n",
    "                    out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "                    dice_score += dice_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                    iou_score += jaccard_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                \n",
    "                dice_score /= len(valid_loader)\n",
    "                iou_score /= len(valid_loader)\n",
    "                print(\"epoch=\", epoch,\n",
    "                    \"dice_score=\", dice_score,\n",
    "                    \"iou_score=\", iou_score)\n",
    "\n",
    "                print(\"------------------------------------------------------------------\")\n",
    "                log_writer.add_scalar(tag=\"dice_scalar\", scalar_value=dice_score, global_step=epoch)\n",
    "                log_writer.add_scalar(tag=\"iou_scalar\", scalar_value=iou_score, global_step=epoch)\n",
    "                #原作者的save方法,封装更多内容 \n",
    "                misc.save_model(args=args, model=model, model_without_ddp=model, optimizer=optimizer,\n",
    "                loss_scaler=loss_scaler, epoch=epoch)\n",
    "                #torch官方save方法\n",
    "                torch.save(model.state_dict(), '/data/zhanghao/skull_project/MODEL/cangku_cc359_ViT_fine_tune/' +\n",
    "                                    str(epoch) + 'ViT' + str(dice_score) + '.pth')\n",
    "                \n",
    "\n",
    "            #早停\n",
    "            if epoch > 20:\n",
    "                min = 999\n",
    "                for i in range(int(epoch/4 - 5) , int(epoch/4 - 1) ):\n",
    "                    if dice_list[i] < min:\n",
    "                        min = dice_list[i]\n",
    "                if dice_score < min:\n",
    "                    lr /= 10\n",
    "                    print(lr)\n",
    "                    if lr < 1e-6:\n",
    "                        break\n",
    "\n",
    "            dice_list.append(dice_score)#依次放入epoch为0 4 8 12 16 20 24....\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     'epoch': epoch, }\n",
    "\n",
    "        if args.output_dir and misc.is_main_process():\n",
    "            if log_writer is not None:\n",
    "                log_writer.flush()\n",
    "            with open(os.path.join(args.output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained checkpoint from: /data/zhanghao/skull_project/mae-main/mae_medical_base_pretrain/checkpoint-399.pth\n",
      "Model = SegVit3D(\n",
      "  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "  (encoder): SegViT3D_Encoder(\n",
      "    (patch_embed): PatchEmbed(\n",
      "      (proj): Conv2d(1, 256, kernel_size=(16, 16), stride=(16, 16))\n",
      "      (norm): Identity()\n",
      "    )\n",
      "    (blocks): ModuleList(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "          (act): GELU()\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (blocks): ModuleList(\n",
      "    (0): BasicLayer(\n",
      "      dim=256, input_resolution=(196, 160), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=4, window_size=4, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=4\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=4, window_size=4, shift_size=2, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=4\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): BasicLayer(\n",
      "      dim=256, input_resolution=(196, 160), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=8, window_size=4, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=8\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=8, window_size=4, shift_size=2, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=8\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): BasicLayer(\n",
      "      dim=256, input_resolution=(196, 160), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=16, window_size=4, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=16\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=16, window_size=4, shift_size=2, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=16\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): BasicLayer(\n",
      "      dim=256, input_resolution=(196, 160), depth=2\n",
      "      (blocks): ModuleList(\n",
      "        (0): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=32, window_size=4, shift_size=0, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=32\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          dim=256, input_resolution=(196, 160), num_heads=32, window_size=4, shift_size=2, mlp_ratio=4.0\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            dim=256, window_size=(4, 4), num_heads=32\n",
      "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path): DropPath()\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (act): GELU()\n",
      "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "number of params (M): 6.32\n",
      "actual lr: 1.00e-04\n",
      "accumulate grad iterations: 1\n",
      "effective batch size: 64\n",
      "查看optimizer =  AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 1.0\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.0625\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 2\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.0625\n",
      "    weight_decay: 0.0005\n",
      "\n",
      "Parameter Group 3\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.125\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 4\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.125\n",
      "    weight_decay: 0.0005\n",
      "\n",
      "Parameter Group 5\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.25\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 6\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.25\n",
      "    weight_decay: 0.0005\n",
      "\n",
      "Parameter Group 7\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.5\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 8\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    lr_scale: 0.5\n",
      "    weight_decay: 0.0005\n",
      ")\n",
      "Start training for 300 epochs\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000020  loss: 0.7352 (0.7440)\n",
      "epoch= 0 dice_score= 0.22324775367282157 iou_score= 0.12586486755415452\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000040  loss: 0.7297 (0.7298)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000060  loss: 0.7200 (0.7200)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000080  loss: 0.7065 (0.7147)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.7001 (0.7097)\n",
      "epoch= 4 dice_score= 0.35346599650937455 iou_score= 0.2152406098537667\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.7191 (0.7063)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6896 (0.7025)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.7106 (0.6991)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6925 (0.6955)\n",
      "epoch= 8 dice_score= 0.5472515211548916 iou_score= 0.3774137240509654\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6900 (0.6923)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6935 (0.6886)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6911 (0.6847)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6844 (0.6811)\n",
      "epoch= 12 dice_score= 0.594785404759784 iou_score= 0.4243244438670402\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6836 (0.6774)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6716 (0.6735)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6688 (0.6696)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6568 (0.6658)\n",
      "epoch= 16 dice_score= 0.6105558387068815 iou_score= 0.4405166229536367\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000100  loss: 0.6514 (0.6616)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6553 (0.6574)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6289 (0.6529)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6481 (0.6486)\n",
      "epoch= 20 dice_score= 0.6853367533794669 iou_score= 0.5220454584720523\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6395 (0.6443)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6423 (0.6397)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6125 (0.6348)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6366 (0.6300)\n",
      "epoch= 24 dice_score= 0.6779782245325487 iou_score= 0.5136199337105418\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6260 (0.6254)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6032 (0.6201)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000099  loss: 0.6259 (0.6156)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.6016 (0.6106)\n",
      "epoch= 28 dice_score= 0.6439752758935441 iou_score= 0.4754939460477164\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.5897 (0.6057)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.5889 (0.5999)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.5901 (0.5945)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.5673 (0.5894)\n",
      "epoch= 32 dice_score= 0.7009714245796204 iou_score= 0.5396863679553188\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000098  loss: 0.5672 (0.5838)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5701 (0.5785)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5717 (0.5725)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5706 (0.5664)\n",
      "epoch= 36 dice_score= 0.6809867163037144 iou_score= 0.5163715724335161\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5596 (0.5614)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5535 (0.5558)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000097  loss: 0.5429 (0.5494)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000096  loss: 0.5370 (0.5441)\n",
      "epoch= 40 dice_score= 0.6062753380731095 iou_score= 0.43516116987827214\n",
      "------------------------------------------------------------------\n",
      "9.640728312448781e-06\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000096  loss: 0.5529 (0.5380)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000096  loss: 0.5214 (0.5325)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000096  loss: 0.5296 (0.5264)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000096  loss: 0.5139 (0.5207)\n",
      "epoch= 44 dice_score= 0.5752096841501635 iou_score= 0.4038996973703074\n",
      "------------------------------------------------------------------\n",
      "9.557721620119228e-06\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000095  loss: 0.4981 (0.5154)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000095  loss: 0.5142 (0.5095)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000095  loss: 0.4830 (0.5034)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000095  loss: 0.4940 (0.4983)\n",
      "epoch= 48 dice_score= 0.5599680501361226 iou_score= 0.38911962439847547\n",
      "------------------------------------------------------------------\n",
      "9.466536551077648e-06\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000094  loss: 0.4682 (0.4923)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000094  loss: 0.4852 (0.4874)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000094  loss: 0.4747 (0.4819)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000094  loss: 0.4814 (0.4768)\n",
      "epoch= 52 dice_score= 0.5980277103047038 iou_score= 0.4267333794471829\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000093  loss: 0.4669 (0.4726)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000093  loss: 0.4647 (0.4663)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000093  loss: 0.4401 (0.4604)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000093  loss: 0.4508 (0.4548)\n",
      "epoch= 56 dice_score= 0.861695432385733 iou_score= 0.7570768109587735\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000092  loss: 0.4474 (0.4508)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000092  loss: 0.4529 (0.4448)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000092  loss: 0.4207 (0.4404)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000091  loss: 0.4212 (0.4349)\n",
      "epoch= 60 dice_score= 0.8791487923888273 iou_score= 0.7844587481299112\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000091  loss: 0.4252 (0.4314)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000091  loss: 0.4211 (0.4259)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000091  loss: 0.4250 (0.4217)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000090  loss: 0.4055 (0.4169)\n",
      "epoch= 64 dice_score= 0.8930230002070583 iou_score= 0.8068108891331872\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000090  loss: 0.4089 (0.4129)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000090  loss: 0.4033 (0.4098)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000089  loss: 0.3896 (0.4038)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000089  loss: 0.3997 (0.3994)\n",
      "epoch= 68 dice_score= 0.9333984394406163 iou_score= 0.8751817955527195\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000089  loss: 0.3918 (0.3950)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000088  loss: 0.3899 (0.3914)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000088  loss: 0.3795 (0.3869)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000088  loss: 0.3765 (0.3830)\n",
      "epoch= 72 dice_score= 0.9363234736198602 iou_score= 0.8803277140439942\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000087  loss: 0.3791 (0.3789)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000087  loss: 0.3662 (0.3753)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000087  loss: 0.3485 (0.3722)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000086  loss: 0.3641 (0.3688)\n",
      "epoch= 76 dice_score= 0.9366237257802209 iou_score= 0.8808571100234985\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000086  loss: 0.3735 (0.3643)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000085  loss: 0.3607 (0.3613)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000085  loss: 0.3480 (0.3584)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000085  loss: 0.3557 (0.3544)\n",
      "epoch= 80 dice_score= 0.9379993704862373 iou_score= 0.8832906027172887\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000084  loss: 0.3458 (0.3507)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000084  loss: 0.3447 (0.3471)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000083  loss: 0.3417 (0.3445)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000083  loss: 0.3277 (0.3410)\n",
      "epoch= 84 dice_score= 0.9389401660409085 iou_score= 0.8849520392196123\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000083  loss: 0.3266 (0.3378)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000082  loss: 0.3361 (0.3354)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000082  loss: 0.3267 (0.3338)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000081  loss: 0.3288 (0.3290)\n",
      "epoch= 88 dice_score= 0.9404039674027022 iou_score= 0.8875521823417308\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000081  loss: 0.3147 (0.3256)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000081  loss: 0.3161 (0.3232)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000080  loss: 0.3200 (0.3205)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000080  loss: 0.3111 (0.3172)\n",
      "epoch= 92 dice_score= 0.9403752823208653 iou_score= 0.8875088303588158\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000079  loss: 0.3015 (0.3147)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000079  loss: 0.3056 (0.3122)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000079  loss: 0.3113 (0.3095)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000078  loss: 0.3037 (0.3075)\n",
      "epoch= 96 dice_score= 0.9414364764856737 iou_score= 0.8893871667773224\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000078  loss: 0.2969 (0.3043)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000077  loss: 0.2939 (0.3025)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000077  loss: 0.3004 (0.3006)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000076  loss: 0.2975 (0.2969)\n",
      "epoch= 100 dice_score= 0.9417000967402791 iou_score= 0.8898588460545207\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000076  loss: 0.2825 (0.2955)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000075  loss: 0.2848 (0.2912)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000075  loss: 0.2797 (0.2906)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000074  loss: 0.2777 (0.2874)\n",
      "epoch= 104 dice_score= 0.9425044420153595 iou_score= 0.8912897359493167\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000074  loss: 0.2813 (0.2853)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000074  loss: 0.2687 (0.2838)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000073  loss: 0.2750 (0.2809)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000073  loss: 0.2747 (0.2792)\n",
      "epoch= 108 dice_score= 0.94139005555663 iou_score= 0.889311296995296\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000072  loss: 0.2718 (0.2774)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000072  loss: 0.2736 (0.2751)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000071  loss: 0.2598 (0.2722)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000071  loss: 0.2680 (0.2696)\n",
      "epoch= 112 dice_score= 0.9427630069643952 iou_score= 0.8917547727740088\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000070  loss: 0.2605 (0.2673)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000070  loss: 0.2650 (0.2664)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000069  loss: 0.2609 (0.2647)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000069  loss: 0.2550 (0.2621)\n",
      "epoch= 116 dice_score= 0.9427716177563334 iou_score= 0.8917675919310991\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000068  loss: 0.2599 (0.2604)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000068  loss: 0.2575 (0.2583)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000067  loss: 0.2522 (0.2568)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000067  loss: 0.2524 (0.2557)\n",
      "epoch= 120 dice_score= 0.9426522227220757 iou_score= 0.8915557057358497\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000066  loss: 0.2543 (0.2540)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000066  loss: 0.2511 (0.2511)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000065  loss: 0.2401 (0.2504)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000065  loss: 0.2318 (0.2484)\n",
      "epoch= 124 dice_score= 0.944486934085225 iou_score= 0.8948398204736931\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000064  loss: 0.2461 (0.2463)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000064  loss: 0.2442 (0.2458)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000063  loss: 0.2430 (0.2435)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000063  loss: 0.2375 (0.2428)\n",
      "epoch= 128 dice_score= 0.9443415639012359 iou_score= 0.8945842302122782\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000062  loss: 0.2325 (0.2398)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000062  loss: 0.2302 (0.2388)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000061  loss: 0.2407 (0.2368)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000061  loss: 0.2359 (0.2361)\n",
      "epoch= 132 dice_score= 0.9444761636645295 iou_score= 0.8948180162629416\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000060  loss: 0.2368 (0.2343)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000060  loss: 0.2229 (0.2324)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000059  loss: 0.2313 (0.2320)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000059  loss: 0.2249 (0.2303)\n",
      "epoch= 136 dice_score= 0.9450692950293075 iou_score= 0.8958889176679212\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000058  loss: 0.2236 (0.2295)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000058  loss: 0.2211 (0.2274)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000057  loss: 0.2212 (0.2261)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000057  loss: 0.2302 (0.2249)\n",
      "epoch= 140 dice_score= 0.9453864194626032 iou_score= 0.8964585675749668\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000056  loss: 0.2197 (0.2234)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000056  loss: 0.2202 (0.2234)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000055  loss: 0.2117 (0.2205)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000054  loss: 0.2137 (0.2204)\n",
      "epoch= 144 dice_score= 0.9461487975231436 iou_score= 0.897824787816336\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000054  loss: 0.2126 (0.2187)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000053  loss: 0.2069 (0.2177)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000053  loss: 0.2121 (0.2164)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000052  loss: 0.2166 (0.2174)\n",
      "epoch= 148 dice_score= 0.9461745439573775 iou_score= 0.8978773189145465\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000052  loss: 0.2105 (0.2141)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000051  loss: 0.2137 (0.2129)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000051  loss: 0.2130 (0.2119)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000050  loss: 0.2124 (0.2114)\n",
      "epoch= 152 dice_score= 0.9463663794273554 iou_score= 0.8982163750848104\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000050  loss: 0.2082 (0.2119)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000049  loss: 0.2040 (0.2091)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000049  loss: 0.2094 (0.2078)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000048  loss: 0.2006 (0.2065)\n",
      "epoch= 156 dice_score= 0.9464259092197862 iou_score= 0.898330079954724\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000048  loss: 0.2030 (0.2058)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000047  loss: 0.2002 (0.2048)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000047  loss: 0.1999 (0.2041)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000046  loss: 0.1950 (0.2030)\n",
      "epoch= 160 dice_score= 0.9465506104535835 iou_score= 0.8985535765803138\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000046  loss: 0.1990 (0.2023)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000045  loss: 0.1994 (0.2015)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000044  loss: 0.1986 (0.2014)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000044  loss: 0.2023 (0.1990)\n",
      "epoch= 164 dice_score= 0.9470173453175744 iou_score= 0.8993896232094876\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000043  loss: 0.1977 (0.1987)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000043  loss: 0.1984 (0.1973)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000042  loss: 0.1997 (0.1970)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000042  loss: 0.1878 (0.1957)\n",
      "epoch= 168 dice_score= 0.9466789156891579 iou_score= 0.8987826483194218\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000041  loss: 0.1893 (0.1950)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000041  loss: 0.1935 (0.1943)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000040  loss: 0.1912 (0.1936)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000040  loss: 0.1928 (0.1929)\n",
      "epoch= 172 dice_score= 0.9464775407037069 iou_score= 0.8984260919482209\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000039  loss: 0.1874 (0.1924)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000039  loss: 0.1870 (0.1912)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000038  loss: 0.1877 (0.1919)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000038  loss: 0.1827 (0.1902)\n",
      "epoch= 176 dice_score= 0.9473943807357965 iou_score= 0.9000716237134712\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000037  loss: 0.1916 (0.1894)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000037  loss: 0.1883 (0.1885)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000036  loss: 0.1828 (0.1875)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000036  loss: 0.1886 (0.1872)\n",
      "epoch= 180 dice_score= 0.9475935753001723 iou_score= 0.9004308373429054\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000035  loss: 0.1876 (0.1864)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000035  loss: 0.1910 (0.1872)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000034  loss: 0.1883 (0.1856)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000034  loss: 0.1803 (0.1852)\n",
      "epoch= 184 dice_score= 0.9477714979371359 iou_score= 0.9007516628087953\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000033  loss: 0.1802 (0.1837)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000033  loss: 0.1810 (0.1833)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000032  loss: 0.1803 (0.1848)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000032  loss: 0.1742 (0.1821)\n",
      "epoch= 188 dice_score= 0.9478593288465987 iou_score= 0.9009080154951229\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000031  loss: 0.1804 (0.1819)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000031  loss: 0.1775 (0.1811)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000030  loss: 0.1782 (0.1809)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000030  loss: 0.1772 (0.1795)\n",
      "epoch= 192 dice_score= 0.9481048292891924 iou_score= 0.9013542338859203\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000029  loss: 0.1764 (0.1797)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000029  loss: 0.1741 (0.1792)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000028  loss: 0.1806 (0.1784)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000028  loss: 0.1748 (0.1781)\n",
      "epoch= 196 dice_score= 0.9483021955157436 iou_score= 0.9017096771750339\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000027  loss: 0.1727 (0.1775)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000027  loss: 0.1731 (0.1787)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000027  loss: 0.1761 (0.1774)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000026  loss: 0.1764 (0.1763)\n",
      "epoch= 200 dice_score= 0.9478793088779893 iou_score= 0.9009488723998846\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000026  loss: 0.1770 (0.1757)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000025  loss: 0.1711 (0.1751)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000025  loss: 0.1802 (0.1747)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000024  loss: 0.1702 (0.1743)\n",
      "epoch= 204 dice_score= 0.9481836654419122 iou_score= 0.9014968955239584\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000024  loss: 0.1736 (0.1739)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000023  loss: 0.1731 (0.1738)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000023  loss: 0.1707 (0.1734)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000022  loss: 0.1735 (0.1732)\n",
      "epoch= 208 dice_score= 0.9484290480613708 iou_score= 0.9019396138745684\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000022  loss: 0.1683 (0.1723)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000022  loss: 0.1672 (0.1723)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000021  loss: 0.1713 (0.1718)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000021  loss: 0.1665 (0.1717)\n",
      "epoch= 212 dice_score= 0.9485957054204719 iou_score= 0.9022411787232687\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000020  loss: 0.1688 (0.1709)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000020  loss: 0.1680 (0.1718)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000020  loss: 0.1691 (0.1712)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000019  loss: 0.1698 (0.1705)\n",
      "epoch= 216 dice_score= 0.9483637047368426 iou_score= 0.9018225974814836\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000019  loss: 0.1714 (0.1713)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000018  loss: 0.1653 (0.1693)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000018  loss: 0.1691 (0.1691)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000018  loss: 0.1678 (0.1708)\n",
      "epoch= 220 dice_score= 0.9486419849617537 iou_score= 0.9023241955180501\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000017  loss: 0.1681 (0.1683)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000017  loss: 0.1676 (0.1683)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000016  loss: 0.1696 (0.1677)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000016  loss: 0.1671 (0.1675)\n",
      "epoch= 224 dice_score= 0.9486194252967834 iou_score= 0.9022847649662994\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000016  loss: 0.1613 (0.1685)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000015  loss: 0.1668 (0.1670)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000015  loss: 0.1665 (0.1671)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000014  loss: 0.1617 (0.1673)\n",
      "epoch= 228 dice_score= 0.948781106361123 iou_score= 0.9025766239609829\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000014  loss: 0.1639 (0.1677)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000014  loss: 0.1640 (0.1664)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000013  loss: 0.1647 (0.1662)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000013  loss: 0.1657 (0.1658)\n",
      "epoch= 232 dice_score= 0.9488567751507426 iou_score= 0.9027133071145346\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000013  loss: 0.1621 (0.1654)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000012  loss: 0.1665 (0.1664)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000012  loss: 0.1623 (0.1651)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000012  loss: 0.1626 (0.1647)\n",
      "epoch= 236 dice_score= 0.9488935137903968 iou_score= 0.9027807088785393\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000011  loss: 0.1607 (0.1648)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000011  loss: 0.1656 (0.1661)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000011  loss: 0.1637 (0.1651)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000010  loss: 0.1654 (0.1649)\n",
      "epoch= 240 dice_score= 0.9488263157911079 iou_score= 0.9026581229165543\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000010  loss: 0.1590 (0.1639)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000010  loss: 0.1642 (0.1640)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000010  loss: 0.1635 (0.1641)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000009  loss: 0.1652 (0.1640)\n",
      "epoch= 244 dice_score= 0.948955164399258 iou_score= 0.9028897687446239\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000009  loss: 0.1637 (0.1644)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000009  loss: 0.1548 (0.1650)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000008  loss: 0.1587 (0.1634)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000008  loss: 0.1624 (0.1634)\n",
      "epoch= 248 dice_score= 0.9489873370458913 iou_score= 0.9029494648755982\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000008  loss: 0.1622 (0.1628)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000008  loss: 0.1619 (0.1626)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000007  loss: 0.1578 (0.1627)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000007  loss: 0.1591 (0.1627)\n",
      "epoch= 252 dice_score= 0.9489784919938375 iou_score= 0.902933303699937\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000007  loss: 0.1552 (0.1625)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000007  loss: 0.1627 (0.1625)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000006  loss: 0.1599 (0.1638)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000006  loss: 0.1633 (0.1619)\n",
      "epoch= 256 dice_score= 0.9489959963532382 iou_score= 0.9029655678327694\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000006  loss: 0.1618 (0.1637)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000006  loss: 0.1590 (0.1628)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000005  loss: 0.1590 (0.1617)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000005  loss: 0.1605 (0.1620)\n",
      "epoch= 260 dice_score= 0.9489503890969032 iou_score= 0.9028833134229793\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000005  loss: 0.1568 (0.1629)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000005  loss: 0.1595 (0.1622)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000005  loss: 0.1587 (0.1617)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1575 (0.1616)\n",
      "epoch= 264 dice_score= 0.9490983472313992 iou_score= 0.9031490794447965\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1609 (0.1614)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1603 (0.1622)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1586 (0.1614)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1593 (0.1622)\n",
      "epoch= 268 dice_score= 0.949075112509173 iou_score= 0.9031077554059583\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000004  loss: 0.1579 (0.1614)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1601 (0.1613)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1565 (0.1609)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1542 (0.1611)\n",
      "epoch= 272 dice_score= 0.9490769879762516 iou_score= 0.90311119861381\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1620 (0.1605)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1558 (0.1612)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000003  loss: 0.1585 (0.1625)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1618 (0.1609)\n",
      "epoch= 276 dice_score= 0.9490758929141733 iou_score= 0.9031093661175218\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1629 (0.1608)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1643 (0.1609)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1572 (0.1612)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1535 (0.1617)\n",
      "epoch= 280 dice_score= 0.949090835660003 iou_score= 0.9031364113785499\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1651 (0.1630)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1631 (0.1609)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1588 (0.1607)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1582 (0.1605)\n",
      "epoch= 284 dice_score= 0.9491295232329258 iou_score= 0.903206331785335\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000002  loss: 0.1603 (0.1614)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1600 (0.1607)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1582 (0.1620)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1630 (0.1613)\n",
      "epoch= 288 dice_score= 0.9491120036258254 iou_score= 0.9031750254852827\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1579 (0.1613)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1571 (0.1603)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1588 (0.1603)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1556 (0.1603)\n",
      "epoch= 292 dice_score= 0.9491482973098755 iou_score= 0.9032404311867648\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1551 (0.1608)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1555 (0.1607)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1594 (0.1604)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1598 (0.1601)\n",
      "epoch= 296 dice_score= 0.9491423410038615 iou_score= 0.903229086898094\n",
      "------------------------------------------------------------------\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1533 (0.1602)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1596 (0.1603)\n",
      "log_dir: ./my_ViT_finetune_seg_base_3d\n",
      "Averaged stats: lr: 0.000001  loss: 0.1593 (0.1599)\n",
      "Training time 8:09:04\n"
     ]
    }
   ],
   "source": [
    "args = get_args_parser()\n",
    "args = args.parse_args(args=[])\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "main(args)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ZH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
