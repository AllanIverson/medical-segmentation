{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 - 2021 MONAI Consortium\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data.distributed\n",
    "import unetr\n",
    "from timm.utils.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "# from trainer import run_training\n",
    "\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.losses import DiceCELoss, DiceLoss\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import Activations, AsDiscrete, Compose\n",
    "from monai.utils.enums import MetricReduction\n",
    "\n",
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "# --------------------------------------------------------\n",
    "# References:\n",
    "# DeiT: https://github.com/facebookresearch/deit\n",
    "# BEiT: https://github.com/microsoft/unilm/tree/master/beit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "# assert timm.__version__ == \"0.3.2\" # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_vit\n",
    "\n",
    "from engine_finetune import train_one_epoch, evaluate\n",
    "\n",
    "\n",
    "def get_args_parser():\n",
    "    parser = argparse.ArgumentParser('MAE fine-tuning for image segmentation with UNETR', add_help=False)\n",
    "    parser.add_argument('--batch_size', default=64, type=int,\n",
    "                        help='Batch size per GPU (effective batch size is batch_size * accum_iter * # gpus')\n",
    "    parser.add_argument('--epochs', default=200, type=int)\n",
    "    parser.add_argument('--accum_iter', default=1, type=int,\n",
    "                        help='Accumulate gradient iterations (for increasing the effective batch size under memory constraints)')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--encoder_model', default='mae3d_144_base_patch16', type=str, metavar='MODEL',\n",
    "                        help='Name of encoder pretrained')\n",
    "\n",
    "    # parser.add_argument('--model',default='mae_vit3d_medical_768_512_extra_windowsize4',type=str,\n",
    "    #                     help='Name of model to train')\n",
    "    #  use UNETR as decoder-model\n",
    "\n",
    "    parser.add_argument('--input_size', default=144, type=int,\n",
    "                        help='images input size')\n",
    "\n",
    "    parser.add_argument('--drop_path', type=float, default=0.1, metavar='PCT',\n",
    "                        help='Drop path rate (default: 0.1)')\n",
    "    \n",
    "\n",
    "\n",
    "    # Optimizer parameters\n",
    "    parser.add_argument('--clip_grad', type=float, default=None, metavar='NORM',\n",
    "                        help='Clip gradient norm (default: None, no clipping)')\n",
    "    parser.add_argument('--weight_decay', type=float, default=0.05,\n",
    "                        help='weight decay (default: 0.05)')\n",
    "\n",
    "    parser.add_argument('--lr', type=float, default=1e-4, metavar='LR',\n",
    "                        help='learning rate (absolute lr)')\n",
    "    parser.add_argument('--blr', type=float, default=1e-4, metavar='LR',\n",
    "                        help='base learning rate: absolute_lr = base_lr * total_batch_size / 256')\n",
    "    parser.add_argument('--layer_decay', type=float, default=0.1,\n",
    "                        help='layer-wise lr decay from ELECTRA/BEiT')\n",
    "\n",
    "    parser.add_argument('--min_lr', type=float, default=1e-6, metavar='LR',\n",
    "                        help='lower lr bound for cyclic schedulers that hit 0')\n",
    "\n",
    "    parser.add_argument('--warmup_epochs', type=int, default=50, metavar='N',\n",
    "                        help='epochs to warmup LR')\n",
    "\n",
    "    # Augmentation parameters\n",
    "    parser.add_argument('--color_jitter', type=float, default=None, metavar='PCT',\n",
    "                        help='Color jitter factor (enabled only when not using Auto/RandAug)')\n",
    "    parser.add_argument('--aa', type=str, default='rand-m9-mstd0.5-inc1', metavar='NAME',\n",
    "                        help='Use AutoAugment policy. \"v0\" or \"original\". \" + \"(default: rand-m9-mstd0.5-inc1)'),\n",
    "    parser.add_argument('--smoothing', type=float, default=0.1,\n",
    "                        help='Label smoothing (default: 0.1)')\n",
    "\n",
    "    # * Random Erase params\n",
    "    parser.add_argument('--reprob', type=float, default=0.25, metavar='PCT',\n",
    "                        help='Random erase prob (default: 0.25)')\n",
    "    parser.add_argument('--remode', type=str, default='pixel',\n",
    "                        help='Random erase mode (default: \"pixel\")')\n",
    "    parser.add_argument('--recount', type=int, default=1,\n",
    "                        help='Random erase count (default: 1)')\n",
    "    parser.add_argument('--resplit', action='store_true', default=False,\n",
    "                        help='Do not random erase first (clean) augmentation split')\n",
    "\n",
    "    # * Mixup params\n",
    "    parser.add_argument('--mixup', type=float, default=0,\n",
    "                        help='mixup alpha, mixup enabled if > 0.')\n",
    "    parser.add_argument('--cutmix', type=float, default=0,\n",
    "                        help='cutmix alpha, cutmix enabled if > 0.')\n",
    "    parser.add_argument('--cutmix_minmax', type=float, nargs='+', default=None,\n",
    "                        help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
    "    parser.add_argument('--mixup_prob', type=float, default=1.0,\n",
    "                        help='Probability of performing mixup or cutmix when either/both is enabled')\n",
    "    parser.add_argument('--mixup_switch_prob', type=float, default=0.5,\n",
    "                        help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
    "    parser.add_argument('--mixup_mode', type=str, default='batch',\n",
    "                        help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
    "\n",
    "    # * Finetuning params\n",
    "    parser.add_argument('--finetune', default=\"/data2/zhanghao/mae_project/pretrain_model/oa_ad_pre800_freezepc/checkpoint-499.pth\",\n",
    "                        help='finetune from checkpoint')\n",
    "    parser.add_argument('--global_pool', action='store_true')\n",
    "    parser.set_defaults(global_pool=True)\n",
    "    parser.add_argument('--cls_token', action='store_false', dest='global_pool',\n",
    "                        help='Use class token instead of global pool for classification')\n",
    "\n",
    "    # Dataset parameters\n",
    "    parser.add_argument('--data_path', default='/datasets01/imagenet_full_size/061417/', type=str,\n",
    "                        help='dataset path')\n",
    "    parser.add_argument('--nb_classes', default=1000, type=int,\n",
    "                        help='number of the classification types')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='/data2/zhanghao/mae_project/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze/',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--log_dir', default='/data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze',\n",
    "                        help='path where to tensorboard log')\n",
    "    parser.add_argument('--device', default='cuda:2',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=0, type=int)\n",
    "    parser.add_argument('--resume', default='',\n",
    "                        help='resume from checkpoint')\n",
    "\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    parser.add_argument('--eval', action='store_true',\n",
    "                        help='Perform evaluation only')\n",
    "    parser.add_argument('--dist_eval', action='store_true', default=False,\n",
    "                        help='Enabling distributed evaluation (recommended during training for faster monitor')\n",
    "    parser.add_argument('--num_workers', default=10, type=int)\n",
    "    parser.add_argument('--pin_mem', action='store_true',\n",
    "                        help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
    "    parser.add_argument('--no_pin_mem', action='store_false', dest='pin_mem')\n",
    "    parser.set_defaults(pin_mem=True)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--local_rank', default=-1, type=int)\n",
    "    parser.add_argument('--dist_on_itp', action='store_true')\n",
    "    parser.add_argument('--dist_url', default='env://',\n",
    "                        help='url used to set up distributed training')\n",
    "\n",
    "    parser.add_argument(\"--norm_name\", default=\"instance\", type=str, help=\"normalization layer type in decoder\")\n",
    "    parser.add_argument(\"--reg_weight\", default=1e-5, type=float, help=\"regularization weight\")\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from util.oasisdataset3d import *\n",
    "import util.oasis4_35_seg_dataset as oa\n",
    "train_path = oa.getPathList() \n",
    "train_loader = oa.getDataloader_all(train_path,B1=5)\n",
    "len(train_loader)\n",
    "# for data in train_loader:\n",
    "#     print(data['image'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import arg\n",
    "\n",
    "from unetr import UNETR\n",
    "import util.lr_sched as lr_sched\n",
    "import math\n",
    "import sys\n",
    "import models_vit3d\n",
    "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
    "from timm.utils.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "from util.diceloss import DiceLoss\n",
    "import torch.nn as nn\n",
    "from my_metric import cal_dice,cal_mIoU\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "def main(args):\n",
    "    device = torch.device(args.device)\n",
    "\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "\n",
    "    # fix the seed for reproducibility\n",
    "    seed = args.seed + misc.get_rank()\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed) \n",
    "\n",
    "    cudnn.benchmark = True  \n",
    "    \n",
    "    #load encoder\n",
    "    encoder = models_vit3d.__dict__[args.encoder_model]()\n",
    "\n",
    "    #load dict\n",
    "    checkpoiont = torch.load(args.finetune,map_location='cpu')\n",
    "    print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "    checkpoint_model = checkpoiont['model']\n",
    "\n",
    "    state_dict = encoder.state_dict()\n",
    "    for k in ['head.weight', 'head.bias']:\n",
    "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "\n",
    "    msg = encoder.load_state_dict(checkpoint_model, strict=False)\n",
    "    print(msg)\n",
    "\n",
    "\n",
    "    # 冻结patch_embeding\n",
    "    for name,param in encoder.named_parameters():\n",
    "        if name=='patch_embed.proj.weight':\n",
    "                param.requires_grad = False\n",
    "                print('freeze ',name)\n",
    "        if name=='patch_embed.proj.bias':\n",
    "                param.requires_grad = False\n",
    "                print('freeze ',name)\n",
    "\n",
    "    # # 冻结encoder\n",
    "    # cnt = 0\n",
    "    # for name,param in model.named_parameters():\n",
    "    #     if cnt == 115: \n",
    "    #         print('freeze to',name)\n",
    "    #         break\n",
    "    #     param.requires_grad = False\n",
    "    #     cnt+=1\n",
    "    \n",
    "    # print(msg)\n",
    "    encoder.to(device)\n",
    "\n",
    "    #define model\n",
    "    model = UNETR(\n",
    "        in_channels=1,\n",
    "        out_channels=5,\n",
    "        img_size=(176,144,144),\n",
    "        feature_size=16,\n",
    "        hidden_size=768,\n",
    "        mlp_ratio=4.,\n",
    "        num_heads=12,\n",
    "        norm_name=args.norm_name,\n",
    "        conv_block=True,\n",
    "        res_block=True,\n",
    "        dropout_rate=args.drop_path,\n",
    "        encoder=encoder)\n",
    "\n",
    "    #load pre-fintune model\n",
    "    # model_path =\"/data2/zhanghao/mae_project/case1_finetune/base_onlyoa_pre800_testoncc/152ViT0.9803611061402729.pth\"\n",
    "    # model.load_state_dict(torch.load(model_path))\n",
    "    # print(\"model is loaded from path:\",model_path)\n",
    "\n",
    "    # 冻结encoder\n",
    "    # cnt = 0\n",
    "    # for name,param in model.named_parameters():\n",
    "    #     if cnt == 115: \n",
    "    #         print('freeze to',name)\n",
    "    #         break\n",
    "    #     param.requires_grad = False\n",
    "    #     cnt+=1\n",
    "    # 冻结patch_embeding\n",
    "    # for name,param in encoder.named_parameters():\n",
    "    #     if name=='patch_embed.proj.weight':\n",
    "    #             param.requires_grad = False\n",
    "    #             print('freeze ',name)\n",
    "    #     if name=='patch_embed.proj.bias':\n",
    "    #             param.requires_grad = False\n",
    "    #             print('freeze ',name)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model_without_ddp = model\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "    # print(\"Model = %s\" % str(model_without_ddp))\n",
    "    print('number of params (M): %.2f' % (n_parameters / 1.e6))\n",
    "\n",
    "    eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "\n",
    "    print(\"actual lr: %.2e\" % args.lr)\n",
    "\n",
    "    print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "    print(\"effective batch size: %d\" % eff_batch_size)\n",
    "    # #加了layer_decay\n",
    "    # param_groups = lrd.param_groups_lrd(model_without_ddp, args.weight_decay,\n",
    "    #     layer_decay=args.layer_decay\n",
    "    # )\n",
    "    # param_groups = optim_factory.param_groups_weight_decay(\n",
    "    #     model_without_ddp, args.weight_decay)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(model_without_ddp.parameters(), lr=args.lr,weight_decay=args.reg_weight)\n",
    "    scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer, warmup_epochs=args.warmup_epochs, max_epochs=args.epochs\n",
    "        )\n",
    "\n",
    "    \n",
    "    print(\"查看optimizer = \",optimizer)\n",
    "    loss_scaler = NativeScaler() \n",
    "\n",
    "    misc.load_model(args=args, model_without_ddp=model_without_ddp, optimizer=optimizer, loss_scaler=loss_scaler)\n",
    "\n",
    "    print(f\"Start training for {args.epochs} epochs\")\n",
    "    dice_list = []\n",
    "    start_time = time.time()\n",
    "    LOSS = torch.nn.CrossEntropyLoss()\n",
    "    print('开始训练')\n",
    "\n",
    "    for epoch in range(args.start_epoch, args.epochs):\n",
    "        #----------------------------训练---------------------------------------------\n",
    "        model.train()\n",
    "        metric_logger = misc.MetricLogger(delimiter=\"  \")\n",
    "        metric_logger.add_meter('lr', misc.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "        accum_iter = args.accum_iter\n",
    "        optimizer.zero_grad()#优化器清零\n",
    "        if log_writer is not None:\n",
    "            print('log_dir: {}'.format(log_writer.log_dir))\n",
    "\n",
    "        for data_iter_step,data in enumerate(train_loader):\n",
    "            if data_iter_step % accum_iter == 0:\n",
    "                lr_sched.adjust_learning_rate(optimizer, data_iter_step / len(train_loader) + epoch, args)\n",
    "            samples = data[\"image\"]  # 我自己的数据是data[\"image\"]表示图片\n",
    "            labeles = data[\"mask4\"]\n",
    "            # print(\"mask.shape = \",labeles.shape)\n",
    "            # print(\"samples.shape = \",samples.shape)\n",
    "            # print(\"mask.type = \",labeles.dtype)\n",
    "            samples = samples.to(device, non_blocking=True)\n",
    "            labeles = labeles.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                out = model(samples)\n",
    "\n",
    "                loss = LOSS(out,labeles)\n",
    "\n",
    "\n",
    "            loss_value = loss.item()\n",
    "\n",
    "\n",
    "            if not math.isfinite(loss_value):\n",
    "                print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "                sys.exit(1)\n",
    "\n",
    "            loss /= accum_iter\n",
    "            loss_scaler(loss, optimizer, parameters=model.parameters(),update_grad=(data_iter_step + 1) % accum_iter == 0)\n",
    "\n",
    "            if (data_iter_step + 1) % accum_iter == 0:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "\n",
    "            metric_logger.update(loss=loss_value)\n",
    "\n",
    "            lr = optimizer.param_groups[0][\"lr\"]\n",
    "            metric_logger.update(lr=lr)\n",
    "\n",
    "            loss_value_reduce = misc.all_reduce_mean(loss_value)\n",
    "\n",
    "            if log_writer is not None :\n",
    "                \"\"\" We use epoch_1000x as the x-axis in tensorboard.\n",
    "                This calibrates different curves when batch size changes.\n",
    "                \"\"\"\n",
    "                epoch_1000x = int(\n",
    "                    (data_iter_step / len(train_loader) + epoch) * 1000)\n",
    "                log_writer.add_scalar('train_loss', loss_value_reduce, epoch_1000x)\n",
    "                log_writer.add_scalar('lr', lr, epoch_1000x)\n",
    "\n",
    "        # gather the stats from all processes\n",
    "        metric_logger.synchronize_between_processes()\n",
    "        print(\"Averaged stats:\", metric_logger)\n",
    "        train_stats = {k: meter.global_avg for k, meter in metric_logger.meters.items()}\n",
    "\n",
    "        #----------------------------验证-----------------------------------------------\n",
    "        #每4个epoch进行一次验证\n",
    "        if(epoch%4==0):\n",
    "            with torch.no_grad(): #表示在验证的时候不需要梯度计算\n",
    "                model.eval()\n",
    "                dice_score = 0.\n",
    "                iou_score = 0.\n",
    "                train_dice = 0.\n",
    "                train_iou = 0.\n",
    "                ccdice_score = 0.\n",
    "                cciou_score = 0.\n",
    "                \n",
    "                for data in train_loader:\n",
    "                    train_image = data[\"image\"]\n",
    "                    train_target = data[\"mask4\"]\n",
    "                    train_image = train_image.to(device, non_blocking=True)\n",
    "                    train_target = train_target.to(device, non_blocking=True)\n",
    "\n",
    "                    out = model(train_image).cpu() #[N,196,256]\n",
    "                    # out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "                    out = np.argmax(out, axis=1)\n",
    "                    train_dice += cal_dice(out.cpu(), train_target.cpu(),classes=5,background_id=0)\n",
    "                    train_iou += cal_mIoU(out.cpu(), train_target.cpu(),classes=5,background_id=0)\n",
    "\n",
    "                # for data in valid_loader:\n",
    "                #     valid_image = data[\"image\"]\n",
    "                #     valid_target = data[\"mask\"]\n",
    "\n",
    "                #     valid_image = valid_image.to(device, non_blocking=True)\n",
    "                #     valid_target = valid_target.to(device, non_blocking=True)\n",
    "                    \n",
    "                #     out = model(valid_image).cpu() #[N,196,256]\n",
    "                #     # out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "                #     out = np.argmax(out, axis=0)\n",
    "                #     dice_score += cal_dice(out.cpu(), valid_target.cpu())\n",
    "                #     iou_score += cal_mIoU(out.cpu(), valid_target.cpu())\n",
    "\n",
    "                # for data in ccvalid_loader:\n",
    "                #     test_image = data[\"image\"]\n",
    "                #     test_target = data[\"mask\"]\n",
    "\n",
    "                #     test_image = test_image.to(device, non_blocking=True)\n",
    "                #     test_target = test_target.to(device, non_blocking=True)\n",
    "\n",
    "                #     out = model(test_image) #[N,196,256]\n",
    "                #     # out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "                #     ccdice_score += dice_coef_metric(out.cpu(), test_target.cpu())\n",
    "                #     cciou_score += jaccard_coef_metric(out.cpu(), test_target.cpu())\n",
    "\n",
    "                train_dice /= len(train_loader)\n",
    "                train_iou /= len(train_loader)\n",
    "                # dice_score /= len(valid_loader)\n",
    "                # iou_score /= len(valid_loader)\n",
    "                # ccdice_score /= len(ccvalid_loader)\n",
    "                # cciou_score /= len(ccvalid_loader)\n",
    "                print(\"epoch=\", epoch,\n",
    "                    \"train_dice=\",train_dice,\n",
    "                    \"train_iou=\",train_iou,)\n",
    "                    # \"dice_score=\", dice_score,\n",
    "                    # \"iou_score=\", iou_score)\n",
    "\n",
    "                print(\"------------------------------------------------------------------\")\n",
    "                log_writer.add_scalar(\"train_dice\",train_dice, global_step=epoch)\n",
    "                log_writer.add_scalar('train_iou',train_iou, global_step=epoch)\n",
    "                #原作者的save方法,封装更多内容 \n",
    "                # misc.save_model(args=args, model=model, model_without_ddp=model, optimizer=optimizer,\n",
    "                # loss_scaler=loss_scaler, epoch=epoch)\n",
    "                #torch官方save方法\n",
    "                # torch.save(model.state_dict(), './seg_768_512_win4_b6_3d_oasis_005data/' +\n",
    "                #                     str(epoch) + 'ViT' + str(dice_score) + '.pth')\n",
    "                \n",
    "\n",
    "            #早停\n",
    "            if epoch > 20:\n",
    "                min = 999\n",
    "                for i in range(int(epoch/4 - 5) , int(epoch/4 - 1) ):\n",
    "                    if dice_list[i] < min:\n",
    "                        min = dice_list[i]\n",
    "                    torch.save(model.state_dict(), args.output_dir+\n",
    "                        str(epoch) + 'ViT' + str(dice_score) + '.pth')    \n",
    "                if dice_score < min:\n",
    "                    lr /= 10\n",
    "                    print(lr)\n",
    "                    \n",
    "                    if lr < 1e-8:\n",
    "                        break\n",
    "                \n",
    "            dice_list.append(dice_score)#依次放入epoch为0 4 8 12 16 20 24....\n",
    "\n",
    "        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n",
    "                     'epoch': epoch, }\n",
    "\n",
    "        if args.output_dir and misc.is_main_process():\n",
    "            if log_writer is not None:\n",
    "                log_writer.flush()\n",
    "            with open(os.path.join(args.output_dir, \"log.txt\"), mode=\"a\", encoding=\"utf-8\") as f:\n",
    "                f.write(json.dumps(log_stats) + \"\\n\")\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "    total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "    print('Training time {}'.format(total_time_str))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained checkpoint from: /data2/zhanghao/mae_project/pretrain_model/oa_ad_pre800_freezepc/checkpoint-499.pth\n",
      "_IncompatibleKeys(missing_keys=['pos_embed', 'head.weight', 'head.bias'], unexpected_keys=['mask_token', 'decoder_pos_embed_class', 'decoder_pos_embed_spatial', 'decoder_pos_embed_temporal', 'decoder_embed.weight', 'decoder_embed.bias', 'decoder_blocks.0.norm1.weight', 'decoder_blocks.0.norm1.bias', 'decoder_blocks.0.attn.qkv.weight', 'decoder_blocks.0.attn.qkv.bias', 'decoder_blocks.0.attn.proj.weight', 'decoder_blocks.0.attn.proj.bias', 'decoder_blocks.0.norm2.weight', 'decoder_blocks.0.norm2.bias', 'decoder_blocks.0.mlp.fc1.weight', 'decoder_blocks.0.mlp.fc1.bias', 'decoder_blocks.0.mlp.fc2.weight', 'decoder_blocks.0.mlp.fc2.bias', 'decoder_blocks.1.norm1.weight', 'decoder_blocks.1.norm1.bias', 'decoder_blocks.1.attn.qkv.weight', 'decoder_blocks.1.attn.qkv.bias', 'decoder_blocks.1.attn.proj.weight', 'decoder_blocks.1.attn.proj.bias', 'decoder_blocks.1.norm2.weight', 'decoder_blocks.1.norm2.bias', 'decoder_blocks.1.mlp.fc1.weight', 'decoder_blocks.1.mlp.fc1.bias', 'decoder_blocks.1.mlp.fc2.weight', 'decoder_blocks.1.mlp.fc2.bias', 'decoder_blocks.2.norm1.weight', 'decoder_blocks.2.norm1.bias', 'decoder_blocks.2.attn.qkv.weight', 'decoder_blocks.2.attn.qkv.bias', 'decoder_blocks.2.attn.proj.weight', 'decoder_blocks.2.attn.proj.bias', 'decoder_blocks.2.norm2.weight', 'decoder_blocks.2.norm2.bias', 'decoder_blocks.2.mlp.fc1.weight', 'decoder_blocks.2.mlp.fc1.bias', 'decoder_blocks.2.mlp.fc2.weight', 'decoder_blocks.2.mlp.fc2.bias', 'decoder_blocks.3.norm1.weight', 'decoder_blocks.3.norm1.bias', 'decoder_blocks.3.attn.qkv.weight', 'decoder_blocks.3.attn.qkv.bias', 'decoder_blocks.3.attn.proj.weight', 'decoder_blocks.3.attn.proj.bias', 'decoder_blocks.3.norm2.weight', 'decoder_blocks.3.norm2.bias', 'decoder_blocks.3.mlp.fc1.weight', 'decoder_blocks.3.mlp.fc1.bias', 'decoder_blocks.3.mlp.fc2.weight', 'decoder_blocks.3.mlp.fc2.bias', 'decoder_norm.weight', 'decoder_norm.bias', 'decoder_pred.weight', 'decoder_pred.bias'])\n",
      "freeze  patch_embed.proj.weight\n",
      "freeze  patch_embed.proj.bias\n",
      "number of params (M): 90.50\n",
      "actual lr: 1.00e-04\n",
      "accumulate grad iterations: 1\n",
      "effective batch size: 64\n",
      "查看optimizer =  Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    initial_lr: 0.0001\n",
      "    lr: 0.0\n",
      "    weight_decay: 1e-05\n",
      ")\n",
      "Start training for 200 epochs\n",
      "开始训练\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000002  loss: 1.4273 (1.4601)\n",
      "epoch= 0 train_dice= 0.13302827273779708 train_iou= 0.07461686829476726\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000004  loss: 1.2539 (1.3253)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000006  loss: 1.1032 (1.1573)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000008  loss: 1.0021 (1.0371)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000010  loss: 0.9326 (0.9559)\n",
      "epoch= 4 train_dice= 0.3064876691099993 train_iou= 0.20683260278040264\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000012  loss: 0.8881 (0.9053)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000014  loss: 0.8416 (0.8612)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000016  loss: 0.8022 (0.8171)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000018  loss: 0.7607 (0.7793)\n",
      "epoch= 8 train_dice= 0.5336416795453492 train_iou= 0.4014173869449272\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000020  loss: 0.7241 (0.7407)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000022  loss: 0.6955 (0.7076)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000024  loss: 0.6685 (0.6776)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000026  loss: 0.6360 (0.6490)\n",
      "epoch= 12 train_dice= 0.7769662929605304 train_iou= 0.6429286442265367\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000028  loss: 0.6073 (0.6208)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000030  loss: 0.5811 (0.5922)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000032  loss: 0.5528 (0.5642)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000034  loss: 0.5223 (0.5358)\n",
      "epoch= 16 train_dice= 0.8045486358694477 train_iou= 0.6803325833408851\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000036  loss: 0.4947 (0.5083)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000038  loss: 0.4724 (0.4817)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000040  loss: 0.4440 (0.4564)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000042  loss: 0.4217 (0.4323)\n",
      "epoch= 20 train_dice= 0.821294010526424 train_iou= 0.7037781247486489\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000044  loss: 0.4008 (0.4089)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000046  loss: 0.3757 (0.3864)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000048  loss: 0.3513 (0.3623)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000050  loss: 0.3312 (0.3403)\n",
      "epoch= 24 train_dice= 0.8486155941899783 train_iou= 0.7411227235077549\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000052  loss: 0.3122 (0.3216)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000054  loss: 0.2970 (0.3036)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000056  loss: 0.2818 (0.2880)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000058  loss: 0.2710 (0.2742)\n",
      "epoch= 28 train_dice= 0.861426462426877 train_iou= 0.7602590050037006\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000060  loss: 0.2535 (0.2609)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000062  loss: 0.2438 (0.2490)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000064  loss: 0.2336 (0.2379)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000066  loss: 0.2234 (0.2284)\n",
      "epoch= 32 train_dice= 0.868705695625129 train_iou= 0.7713997978145232\n",
      "------------------------------------------------------------------\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000068  loss: 0.2142 (0.2182)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000070  loss: 0.2053 (0.2093)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n",
      "Averaged stats: lr: 0.000072  loss: 0.1992 (0.2010)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/ad_oa_withlabel_nofreeze_seg4/pre500_seg414oa_testoncc_nofreeze\n"
     ]
    }
   ],
   "source": [
    "args = get_args_parser()\n",
    "args = args.parse_args(args=[])\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1, 1, 1],\n",
      "          [1, 1, 1]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "a = torch.ones([1,1,2,3])\n",
    "b = torch.ones([1,1,2,3]).type(torch.LongTensor)\n",
    "\n",
    "# b[0][0][1][0] = 1\n",
    "# b[0][0][1][1] += 1\n",
    "# b[0][0][1][2] += 1\n",
    "# b[0][0][0][1] += 3\n",
    "print(b)\n",
    "\n",
    "c = cal_dice(a,b,classes=2,background_id=0)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.ccdataset3d import *\n",
    "train_path, valid_path, test_path = getPathList()\n",
    "\n",
    "# train_loader = getDataloader(\n",
    "#     valid_path,valid_paths=None,test_paths=None, B1=1)\n",
    "\n",
    "train_loader,valid_loader,test_loader = getDataloader(\n",
    "    train_path,valid_path, test_path,B1=1\n",
    ")\n",
    "len(train_loader),len(valid_loader),len(test_loader)\n",
    "#(1,1,160,224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args_parser()\n",
    "args = args.parse_args(args=[])\n",
    "encoder = models_vit3d.__dict__['mae3d_vit_base_patch16']()\n",
    "finetune_str = \"/data2/zhanghao/mae_project/pretrain_model/3d_oa_cc_base_norm_800/checkpoint-799.pth\"\n",
    "checkpoiont = torch.load(finetune_str,map_location='cpu')\n",
    "checkpoint_model = checkpoiont['model']\n",
    "\n",
    "state_dict = encoder.state_dict()\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "\n",
    "msg = encoder.load_state_dict(checkpoint_model, strict=False)\n",
    "# print(msg)\n",
    "\n",
    "from torch import device\n",
    "import models_vit3d\n",
    "device = device = torch.device('cuda:0')\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=(160,224,224),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_ratio=4.,\n",
    "    num_heads=12,\n",
    "    norm_name=args.norm_name,\n",
    "    conv_block=True,\n",
    "    res_block=True,\n",
    "    dropout_rate=args.drop_path,\n",
    "    encoder=encoder)\n",
    "\n",
    "model_path =\"/data2/zhanghao/mae_project/case_withlabel_nofreeze/pre800_seg340oa_add20cc_testoncc_nofreeze/96ViT0.9792894412731302.pth\"\n",
    "\n",
    "model.to(device)\n",
    "dice_score = 0\n",
    "iou_score = 0\n",
    "\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        test_image = data[\"image\"]\n",
    "        test_target = data[\"mask\"]\n",
    "\n",
    "        test_image = test_image.to(device, non_blocking=True)\n",
    "        test_target = test_target.to(device, non_blocking=True)\n",
    "\n",
    "        out = model(test_image) #[N,196,256]\n",
    "        # out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "        x = dice_coef_metric(out.cpu(), test_target.cpu())\n",
    "        y = jaccard_coef_metric(out.cpu(), test_target.cpu())\n",
    "        dice_score += x\n",
    "        iou_score += y\n",
    "        print(\n",
    "        \"dice_score=\", x,\n",
    "        \"iou_score=\", y)\n",
    "        # cnt += 1\n",
    "        # if cnt == 30: break\n",
    "        \n",
    "    # dice_score /= cnt\n",
    "    # iou_score /= cnt\n",
    "    dice_score /= len(test_loader)\n",
    "    iou_score /= len(test_loader)\n",
    "    print(\n",
    "        \"dice_score=\", dice_score,\n",
    "        \"iou_score=\", iou_score)\n",
    "\n",
    "# cnt = 0\n",
    "# for name,param in model.named_parameters():\n",
    "#     print(cnt,name)\n",
    "#     # break\n",
    "#     param.requires_grad = False\n",
    "#     cnt+=1\n",
    "# print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1,1,160,224,224)\n",
    "b = encoder(a)\n",
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args_parser()\n",
    "args = args.parse_args(args=[])\n",
    "\n",
    "model = UNETR(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    img_size=(160,224,224),\n",
    "    feature_size=16,\n",
    "    hidden_size=768,\n",
    "    mlp_ratio=4.,\n",
    "    num_heads=12,\n",
    "    norm_name=args.norm_name,\n",
    "    conv_block=True,\n",
    "    res_block=True,\n",
    "    dropout_rate=args.drop_path,\n",
    "    encoder=encoder)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1,1,160,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model(a).shape\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr,weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = models_vit3d.__dict__[args.encoder_model]()\n",
    "\n",
    "#load dict\n",
    "checkpoiont = torch.load(args.finetune,map_location='cpu')\n",
    "print(\"Load pre-trained checkpoint from: %s\" % args.finetune)\n",
    "checkpoint_model = checkpoiont['model']\n",
    "\n",
    "state_dict = encoder.state_dict()\n",
    "\n",
    "msg = encoder.load_state_dict(checkpoint_model, strict=False)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for name, para in encoder.named_parameters():\n",
    "    print(cnt,name)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ZH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
