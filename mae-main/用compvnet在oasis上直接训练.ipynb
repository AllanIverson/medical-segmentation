{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanghao/.conda/envs/ZH/lib/python3.9/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from numpy import fliplr, flipud\n",
    "from skimage import img_as_ubyte\n",
    "import itertools\n",
    "import skimage.io\n",
    "# from losses_pytorch import dice_loss\n",
    "# import hausdorff\n",
    "import warnings\n",
    "from albumentations import Compose, HorizontalFlip\n",
    "import albumentations as A\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Image as show_gif\n",
    "import skimage\n",
    "from skimage import util\n",
    "from skimage.util import montage\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "# import seaborn as sns\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# import matplotlib.patches as mpatches\n",
    "# import matplotlib.animation as anim\n",
    "# from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "# import h5py\n",
    "# import nilearn.plotting as nlplt\n",
    "# import nilearn as nl\n",
    "import pydicom as pdm\n",
    "import nibabel as nib\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# from scipy import stats\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "import torch\n",
    "# import torchvision.transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
    "from util.diceloss import DiceLoss\n",
    "\n",
    "\n",
    "KernelSize = 3\n",
    "KernelSizePad = 1\n",
    "SamePadding = 2\n",
    "Stride = 2\n",
    "lr = 0.00001\n",
    "\n",
    "\n",
    "class Double_conv(nn.Module):\n",
    "    #conv->bn->relu->conv->bn->relu\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(16,out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(16,out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=Stride),\n",
    "            Double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_ch,in_ch,kernel_size=2,stride=2)\n",
    "        self.upcv = nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv = Double_conv(in_ch, out_ch)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.upcv(x1)\n",
    "        # diffZ = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        # diffY = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "        # diffX = torch.tensor([x2.size()[4] - x1.size()[4]])\n",
    "        # x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "        #                 diffY // 2, diffY - diffY // 2,\n",
    "        #                 diffZ // 2, diffZ - diffZ // 2, ])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)  # (B,C,D,H,W)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class compVnet(nn.Module):\n",
    "    def __init__(self, bilinear=True):\n",
    "        super(compVnet, self).__init__()\n",
    "        self.bilinear = bilinear\n",
    "        self.inc = Double_conv(1, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        self.down4 = Down(128, 256)\n",
    "        self.up1 = Up(256, 128)\n",
    "        self.up2 = Up(128, 64)\n",
    "        self.up3 = Up(64, 32)\n",
    "        self.up4 = Up(32, 16)\n",
    "        self.outc = OutConv(16, 1)\n",
    "        self.up1x = Up(256, 128)\n",
    "        self.up2x = Up(128, 64)\n",
    "        self.up3x = Up(64, 32)\n",
    "        self.up4x = Up(32, 16)\n",
    "        self.outcx = OutConv(16, 1)\n",
    "        self.incz = Double_conv(1, 16)\n",
    "        self.down1z = Down(16, 32)\n",
    "        self.down2z = Down(32, 64)\n",
    "        self.down3z = Down(64,128)\n",
    "        # self.down4z = Down(128, 256)\n",
    "        self.up1z = Up(256, 128)\n",
    "        self.up2z = Up(128, 64)\n",
    "        self.up3z = Up(64, 32)\n",
    "        self.up4z = Up(32, 16)\n",
    "        self.outcz = OutConv(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        # x5 = self.down4(x4)\n",
    "        x = self.up2(x4, x3)\n",
    "        # x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        y = self.up2x(x4, x3)\n",
    "        # y = self.up2x(y, x3)\n",
    "        y = self.up3x(y, x2)\n",
    "        y = self.up4x(y, x1)\n",
    "        y = self.outcx(y)\n",
    "        # z = torch.cat([x, y], dim=1)\n",
    "        z = torch.sigmoid(x)+torch.sigmoid(y)\n",
    "        z1 = self.incz(z)\n",
    "        z2 = self.down1z(z1)\n",
    "        z3 = self.down2z(z2)\n",
    "        z4 = self.down3z(z3)\n",
    "        # z5 = self.down4z(z4)\n",
    "        z = self.up2z(z4, z3)\n",
    "        # z = self.up2z(z, z3)\n",
    "        z = self.up3z(z, z2)\n",
    "        z = self.up4z(z, z1)\n",
    "        z = self.outcz(z)\n",
    "\n",
    "        return x, y, z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(340, 42, 43)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from util.oasisdataset3d import *\n",
    "train_path, valid_path, test_path = getPathList()\n",
    "train_loader = getDataloader(\n",
    "    train_path, B1=1)\n",
    "_,valid_loader,test_loader = getDataloader(\n",
    "    train_path,valid_path,test_path\n",
    ")\n",
    "len(train_loader),len(valid_loader),len(test_loader)\n",
    "#(1,1,160,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局权重初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('conv3d') != -1:\n",
    "        nn.init.kaiming_normal(m.weight)\n",
    "        m.bias.data.zero()\n",
    "\n",
    "#设置随机种子\n",
    "\n",
    "\n",
    "def seed_everthing(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "def training(epochs, model, trainLoader, validLoader):\n",
    "    dice_list = []\n",
    "    seed_everthing(0)  # 设置全局随机种子\n",
    "    lr = 1e-4\n",
    "    dice_score = 0.\n",
    "    iou_score = 0.\n",
    "    writer = SummaryWriter('/data/zhanghao/skull_project/mae-main/base_line/compvnet_oasis_alldata')\n",
    "    step = 0\n",
    "    weights_init(model)  # 模型权重初始化\n",
    "    Loss = DiceLoss()  # 实例化DiceLoss\n",
    "    model.train()  # 设置model为训练模式\n",
    "\n",
    "#____________________________________训练______________________________________________\n",
    "    for epoch in range(epochs):\n",
    "        # batch_num = 0  # 批次数\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)  # 每个epoch设置一次优化器\n",
    "        model.train()  # 设置为训练模式\n",
    "        optimizer.zero_grad()#优化器清零\n",
    "        for data in trainLoader:  \n",
    "\n",
    "            image = data[\"image\"]  \n",
    "            target = data[\"mask\"]\n",
    "\n",
    "            image = image.cuda(2)\n",
    "            target = target.cuda(2)\n",
    "            out = model(image)\n",
    "            loss = Loss(out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"step=\",step)\n",
    "\n",
    "            writer.add_scalar(tag=\"loss\", scalar_value=loss, global_step=step)\n",
    "            step += 1\n",
    "        print(\"loss=\", loss)\n",
    "\n",
    "        optimizer.zero_grad()#在每轮训练后清零，给验证留出空间\n",
    "\n",
    "#___________________________________验证_______________________________________________\n",
    "        #每4个epoch进行一次验证\n",
    "        if (epoch%4) == 0:\n",
    "            with torch.no_grad():  # 表示在验证的时候不需要进行梯度计算\n",
    "                model.eval()  # 设置model为验证模式\n",
    "                dice_score = 0.\n",
    "                iou_score = 0.\n",
    "                for data in validLoader:  # validLoader共60个nii文件,batch_size=1\n",
    "                    valid_image = data[\"image\"]  \n",
    "                    valid_target = data[\"mask\"]\n",
    "\n",
    "                    valid_image = valid_image.cuda(2)\n",
    "                    valid_target = valid_target.cuda(2)\n",
    "                    out = model(valid_image)\n",
    "                    dice_score += dice_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                    iou_score += jaccard_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                    \n",
    "                dice_score /= len(valid_loader)  # 算出平均dice_score\n",
    "                iou_score /= len(valid_loader)\n",
    "\n",
    "\n",
    "                print(\"epoch=\", epoch,\n",
    "                    \"dice_score=\", dice_score,\n",
    "                    \"iou_score=\", iou_score)\n",
    "\n",
    "                print(\"------------------------------------------------------------------\")\n",
    "                writer.add_scalar(tag=\"dice_scalar\", scalar_value=dice_score, global_step=epoch)\n",
    "                writer.add_scalar(tag=\"iou_scalar\", scalar_value=iou_score, global_step=epoch)\n",
    "                torch.save(model.state_dict(), '/data/zhanghao/skull_project/mae-main/base_line/compvnet_oasis_alldata/' +\n",
    "                                    str(epoch) + 'Vnet' + str(dice_score) + '.pth')\n",
    "\n",
    "        \n",
    "            #早停\n",
    "            if epoch > 20:\n",
    "                min = 999\n",
    "                for i in range(int(epoch/4 - 5) , int(epoch/4 - 1) ):\n",
    "                    if dice_list[i] < min:\n",
    "                        min = dice_list[i]\n",
    "                if dice_score < min:\n",
    "                    lr /= 10\n",
    "                    print(lr)\n",
    "                    if lr < 1e-6:\n",
    "                        break\n",
    "\n",
    "            dice_list.append(dice_score)#依次放入epoch为0 4 8 12 16 20 24....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train_loader)= 340 len(valid_loader)= 42\n"
     ]
    }
   ],
   "source": [
    "print(\"len(train_loader)=\", len(train_loader), \"len(valid_loader)=\", len(valid_loader))\n",
    "model = compVnet()\n",
    "model = model.cuda(2)  \n",
    "# torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.benchmark = True\n",
    "# training(epochs=700, model=model, trainLoader=train_loader, validLoader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given transposed=1, weight of size [256, 256, 2, 2, 2], expected input[1, 128, 20, 28, 28] to have 256 channels, but got 128 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-b3b648346b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-551eb70e3ae3>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epochs, model, trainLoader, validLoader)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-826f84972d21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mx4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# x5 = self.down4(x4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;31m# x = self.up2(x, x3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-826f84972d21>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# diffZ = torch.tensor([x2.size()[2] - x1.size()[2]])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1059\u001b[0m             input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)  # type: ignore[arg-type]\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m         return F.conv_transpose3d(\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             output_padding, self.groups, self.dilation)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given transposed=1, weight of size [256, 256, 2, 2, 2], expected input[1, 128, 20, 28, 28] to have 256 channels, but got 128 channels instead"
     ]
    }
   ],
   "source": [
    "training(epochs=700, model=model, trainLoader=train_loader, validLoader=valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ZH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
