{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "from albumentations import Compose, HorizontalFlip\n",
                "import albumentations as A\n",
                "from torch.nn import MSELoss\n",
                "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
                "from torch.optim import Adam\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from IPython.display import YouTubeVideo\n",
                "from IPython.display import clear_output\n",
                "from IPython.display import Image as show_gif\n",
                "# from skimage.util import montage\n",
                "from skimage.transform import resize\n",
                "import imageio\n",
                "# import seaborn as sns\n",
                "# import matplotlib.gridspec as gridspec\n",
                "# import matplotlib.patches as mpatches\n",
                "# import matplotlib.animation as anim\n",
                "# from matplotlib import cm\n",
                "# import matplotlib.pyplot as plt\n",
                "# import h5py\n",
                "# import nilearn.plotting as nlplt\n",
                "# import nilearn as nl\n",
                "import pydicom as pdm\n",
                "import nibabel as nib\n",
                "from sklearn.model_selection import KFold\n",
                "from sklearn.svm import SVR\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.model_selection import StratifiedKFold\n",
                "from sklearn.model_selection import train_test_split\n",
                "import pandas as pd\n",
                "# from scipy import stats\n",
                "import numpy as np\n",
                "from random import randint\n",
                "import time\n",
                "import os\n",
                "# from tqdm import tqdm\n",
                "import torch\n",
                "# import torchvision.transforms\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader, Dataset\n",
                "from GPUtil import showUtilization as gpu_usage\n",
                "from numba import cuda\n",
                "# import torchvision.transforms as transforms\n",
                "warnings.simplefilter(\"ignore\")\n",
                "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
                "from util.diceloss import DiceLoss\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "KernelSize = 3\n",
                "KernelSizePad = 1\n",
                "SamePadding = 2\n",
                "Stride = 2\n",
                "lr = 0.00001\n",
                "\n",
                "\n",
                "class Double_conv(nn.Module):\n",
                "    #conv->bn->relu->conv->bn->relu\n",
                "    def __init__(self, in_ch, out_ch):\n",
                "        super(Double_conv, self).__init__()\n",
                "        self.conv = nn.Sequential(\n",
                "            nn.Conv3d(in_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
                "            # nn.BatchNorm3d(out_ch),\n",
                "            nn.GroupNorm(16,out_ch),\n",
                "            nn.ReLU(inplace=True),\n",
                "            nn.Conv3d(out_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
                "            # nn.BatchNorm3d(out_ch),\n",
                "            nn.GroupNorm(16,out_ch),\n",
                "            nn.ReLU(inplace=True),\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        x = self.conv(x)\n",
                "        return x\n",
                "\n",
                "\n",
                "class Down(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch):\n",
                "        super(Down, self).__init__()\n",
                "        self.maxpool = nn.Sequential(\n",
                "            nn.MaxPool3d(kernel_size=2, stride=Stride),\n",
                "            Double_conv(in_ch, out_ch)\n",
                "        )\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.maxpool(x)\n",
                "\n",
                "\n",
                "class Up(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch):\n",
                "        super(Up, self).__init__()\n",
                "        self.up = nn.ConvTranspose3d(in_ch,in_ch,kernel_size=2,stride=2)\n",
                "        self.upcv = nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1)\n",
                "        self.conv = Double_conv(in_ch, out_ch)\n",
                "\n",
                "\n",
                "    def forward(self, x1, x2):\n",
                "        x1 = self.up(x1)\n",
                "        x1 = self.upcv(x1)\n",
                "        # diffZ = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
                "        # diffY = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
                "        # diffX = torch.tensor([x2.size()[4] - x1.size()[4]])\n",
                "        # x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
                "        #                 diffY // 2, diffY - diffY // 2,\n",
                "        #                 diffZ // 2, diffZ - diffZ // 2, ])\n",
                "\n",
                "        x = torch.cat([x2, x1], dim=1)  # (B,C,D,H,W)\n",
                "        return self.conv(x)\n",
                "\n",
                "\n",
                "class OutConv(nn.Module):\n",
                "    def __init__(self, in_ch, out_ch):\n",
                "        super(OutConv, self).__init__()\n",
                "        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size=1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.conv(x)\n",
                "\n",
                "\n",
                "class compVnet(nn.Module):\n",
                "    def __init__(self, bilinear=True):\n",
                "        super(compVnet, self).__init__()\n",
                "        self.bilinear = bilinear\n",
                "        self.inc = Double_conv(1, 16)\n",
                "        self.down1 = Down(16, 32)\n",
                "        self.down2 = Down(32, 64)\n",
                "        self.down3 = Down(64, 128)\n",
                "        self.down4 = Down(128, 256)\n",
                "        self.up1 = Up(256, 128)\n",
                "        self.up2 = Up(128, 64)\n",
                "        self.up3 = Up(64, 32)\n",
                "        self.up4 = Up(32, 16)\n",
                "        self.outc = OutConv(16, 1)\n",
                "        self.up1x = Up(256, 128)\n",
                "        self.up2x = Up(128, 64)\n",
                "        self.up3x = Up(64, 32)\n",
                "        self.up4x = Up(32, 16)\n",
                "        self.outcx = OutConv(16, 1)\n",
                "        self.incz = Double_conv(1, 16)\n",
                "        self.down1z = Down(16, 32)\n",
                "        self.down2z = Down(32, 64)\n",
                "        self.down3z = Down(64,128)\n",
                "        self.down4z = Down(128, 256)\n",
                "        self.up1z = Up(256, 128)\n",
                "        self.up2z = Up(128, 64)\n",
                "        self.up3z = Up(64, 32)\n",
                "        self.up4z = Up(32, 16)\n",
                "        self.outcz = OutConv(16, 1)\n",
                "\n",
                "    def forward(self, x):\n",
                "        x1 = self.inc(x)\n",
                "        x2 = self.down1(x1)\n",
                "        x3 = self.down2(x2)\n",
                "        x4 = self.down3(x3)\n",
                "        x5 = self.down4(x4)\n",
                "        x = self.up1(x5, x4)\n",
                "        x = self.up2(x, x3)\n",
                "        x = self.up3(x, x2)\n",
                "        x = self.up4(x, x1)\n",
                "        x = self.outc(x)\n",
                "        y = self.up1x(x5, x4)\n",
                "        y = self.up2x(y, x3)\n",
                "        y = self.up3x(y, x2)\n",
                "        y = self.up4x(y, x1)\n",
                "        y = self.outcx(y)\n",
                "        # z = torch.cat([x, y], dim=1)\n",
                "        z = torch.sigmoid(x)+torch.sigmoid(y)\n",
                "        z1 = self.incz(z)\n",
                "        z2 = self.down1z(z1)\n",
                "        z3 = self.down2z(z2)\n",
                "        z4 = self.down3z(z3)\n",
                "        z5 = self.down4z(z4)\n",
                "        z = self.up1z(z5, z4)\n",
                "        z = self.up2z(z, z3)\n",
                "        z = self.up3z(z, z2)\n",
                "        z = self.up4z(z, z1)\n",
                "        z = self.outcz(z)\n",
                "\n",
                "        return x, y, z\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "#全局权重初始化\n",
                "def weights_init(m):\n",
                "    classname = m.__class__.__name__\n",
                "    if classname.find('conv3d')!=-1:\n",
                "        nn.init.kaiming_normal(m.weight)\n",
                "        m.bias.data.zero()\n",
                "\n",
                "#设置随机种子\n",
                "def seed_everthing(seed:int):\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed(seed)\n",
                "\n",
                "#清空GPU\n",
                "def free_gpu_cache():\n",
                "    print(\"开始清空\")\n",
                "    gpu_usage\n",
                "    torch.cuda.empty_cache()\n",
                "    cuda.select_device(0)\n",
                "    cuda.close()\n",
                "    cuda.select_device(0)\n",
                "    print(\"已清空\")\n",
                "    gpu_usage\n",
                "\n",
                "\n",
                "\n",
                "#数据归一化\n",
                "    \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(274, 43, 42)"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#全局配置文件\n",
                "class GlobalConfig:\n",
                "    root_dir = '/data/zhanghao/data/brats20-dataset-training-validation'\n",
                "    train_root_dir = '/data/zhanghao/data/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
                "    test_root_dir = '/data/zhanghao/data/brats20-dataset-training-validation/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
                "    path_to_csv = '/data/zhanghao/project/train_data.csv'  \n",
                "    seed = 55\n",
                "\n",
                "\n",
                "config = GlobalConfig()\n",
                "\n",
                "from util.ccdataset3d import *\n",
                "train_paths, valid_paths, test_paths = getPathList()\n",
                "train_loader, valid_loader, test_loader = getDataloader(\n",
                "    train_paths, valid_paths, test_paths, B1=1)\n",
                "len(train_loader),len(valid_loader),len(test_loader)\n",
                "#(1,1,160,224,224)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorboardX import SummaryWriter\n",
                "def training(epochs, model, trainLoader, validLoader):\n",
                "    dice_list = []\n",
                "    seed_everthing(config.seed)  # 设置全局随机种子\n",
                "    lr = 1e-4\n",
                "    dice_score = 0.\n",
                "    iou_score = 0.\n",
                "    writer = SummaryWriter('data/zhanghao/MODEL_0.5/compVnet_baseline')\n",
                "    step = 0\n",
                "    weights_init(model)  # 模型权重初始化\n",
                "    Loss = DiceLoss()  # 实例化DiceLoss\n",
                "    model.train()  # 设置model为训练模式\n",
                "\n",
                "#____________________________________训练______________________________________________\n",
                "    for epoch in range(epochs):\n",
                "        # batch_num = 0  # 批次数\n",
                "        optimizer = optim.Adam(model.parameters(), lr=lr)  # 每个epoch设置一次优化器\n",
                "        model.train()  # 设置为训练模式\n",
                "        optimizer.zero_grad()#优化器清零\n",
                "        for data in trainLoader:  \n",
                "\n",
                "            image = data[\"image\"]  # [1,1,96,160,160]\n",
                "            target = data[\"mask\"]\n",
                "\n",
                "            image = image.cuda(0)\n",
                "            target = target.cuda(0)\n",
                "            out1, out2, outx = model(image)\n",
                "            loss1 = Loss(out1, target)\n",
                "            loss2 = -Loss(out2, target)\n",
                "            lossx = F.mse_loss(outx, image)\n",
                "            loss = loss1+loss2+lossx\n",
                "            loss.backward()\n",
                "            optimizer.step()\n",
                "            # print(\"step=\",step)\n",
                "            writer.add_scalar(tag=\"loss1\", scalar_value=loss1, global_step=step)\n",
                "            writer.add_scalar(tag=\"loss2\", scalar_value=loss2, global_step=step)\n",
                "            writer.add_scalar(tag=\"lossx\", scalar_value=lossx, global_step=step)\n",
                "            writer.add_scalar(tag=\"loss\", scalar_value=loss, global_step=step)\n",
                "            step += 1\n",
                "        print(\"loss1=\", loss1, \"loss2=\", loss2, \"lossx=\", lossx, \"loss=\", loss)\n",
                "\n",
                "        optimizer.zero_grad()#在每轮训练后清零，给验证留出空间\n",
                "\n",
                "#___________________________________验证_______________________________________________\n",
                "        #每4个epoch进行一次验证\n",
                "        if (epoch%4) == 0:\n",
                "            with torch.no_grad():  # 表示在验证的时候不需要进行梯度计算\n",
                "                model.eval()  # 设置model为验证模式\n",
                "                dice_score = 0.\n",
                "                iou_score = 0.\n",
                "                for data in validLoader:  # validLoader共60个nii文件,batch_size=1\n",
                "                    valid_image = data[\"image\"]  \n",
                "                    valid_target = data[\"mask\"]\n",
                "\n",
                "                    valid_image = valid_image.cuda(0)\n",
                "                    valid_target = valid_target.cuda(0)\n",
                "                    _, out, _ = model(valid_image)\n",
                "                    dice_score += dice_coef_metric(out.cpu(), valid_target.cpu())\n",
                "                    iou_score += jaccard_coef_metric(out.cpu(), valid_target.cpu())\n",
                "                    \n",
                "                dice_score /= len(validLoader) # 算出平均dice_score\n",
                "                iou_score /= len(validLoader)\n",
                "\n",
                "\n",
                "                print(\"epoch=\", epoch,\n",
                "                    \"dice_score=\", dice_score,\n",
                "                    \"iou_score=\", iou_score)\n",
                "\n",
                "                print(\"------------------------------------------------------------------\")\n",
                "                writer.add_scalar(tag=\"dice_scalar\", scalar_value=dice_score, global_step=epoch)\n",
                "                writer.add_scalar(tag=\"iou_scalar\", scalar_value=iou_score, global_step=epoch)\n",
                "                torch.save(model.state_dict(), '/data/zhanghao/skull_project/mae-main/base_line/compvent_model/' +\n",
                "                                    str(epoch) + 'compVnet(1e-6)_GN' + str(dice_score) + '.pth')\n",
                "\n",
                "        \n",
                "            #早停\n",
                "            if epoch > 20:\n",
                "                min = 999\n",
                "                for i in range(int(epoch/4 - 5) , int(epoch/4 - 1) ):\n",
                "                    if dice_list[i] < min:\n",
                "                        min = dice_list[i]\n",
                "                if dice_score < min:\n",
                "                    lr /= 10\n",
                "                    print(lr)\n",
                "                    if lr < 1e-6:\n",
                "                        torch.save(model.state_dict(), '/data/zhanghao/skull_project/mae-main/base_line/compvent_model/' +\n",
                "                                    str(epoch) + 'compVnet(1e-6)_GN_sigmoid_add' + str(dice_score) + '.pth')\n",
                "                        break\n",
                "\n",
                "            dice_list.append(dice_score)#依次放入epoch为0 4 8 12 16 20 24....\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "len(train_loader)= 274 len(valid_loader)= 43\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 23.70 GiB total capacity; 21.68 GiB already allocated; 292.56 MiB free; 21.95 GiB reserved in total by PyTorch)",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "\u001b[0;32m<ipython-input-6-d4c16db22050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbenchmark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m700\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidLoader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
                        "\u001b[0;32m<ipython-input-5-a92a2b8b18d9>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(epochs, model, trainLoader, validLoader)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mlossx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mloss2\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlossx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# print(\"step=\",step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                        "\u001b[0;32m~/.conda/envs/ZH/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 490.00 MiB (GPU 0; 23.70 GiB total capacity; 21.68 GiB already allocated; 292.56 MiB free; 21.95 GiB reserved in total by PyTorch)"
                    ]
                }
            ],
            "source": [
                "print(\"len(train_loader)=\", len(train_loader), \"len(valid_loader)=\", len(valid_loader))\n",
                "model = compVnet()\n",
                "model = model.cuda(0)  \n",
                "torch.backends.cudnn.enabled = True\n",
                "torch.backends.cudnn.benchmark = True\n",
                "training(epochs=700, model=model, trainLoader=train_loader, validLoader=valid_loader)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.9.6 ('ZH')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
