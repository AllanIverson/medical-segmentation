{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhanghao/.conda/envs/ZH/lib/python3.9/site-packages/skimage/io/manage_plugins.py:23: UserWarning: Your installed pillow version is < 7.1.0. Several security issues (CVE-2020-11538, CVE-2020-10379, CVE-2020-10994, CVE-2020-10177) have been fixed in pillow 7.1.0 or higher. We recommend to upgrade this library.\n",
      "  from .collection import imread_collection_wrapper\n"
     ]
    }
   ],
   "source": [
    "from numpy import fliplr, flipud\n",
    "from skimage import img_as_ubyte\n",
    "import itertools\n",
    "import skimage.io\n",
    "# from losses_pytorch import dice_loss\n",
    "# import hausdorff\n",
    "import warnings\n",
    "from albumentations import Compose, HorizontalFlip\n",
    "import albumentations as A\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from IPython.display import YouTubeVideo\n",
    "from IPython.display import clear_output\n",
    "from IPython.display import Image as show_gif\n",
    "import skimage\n",
    "from skimage import util\n",
    "from skimage.util import montage\n",
    "from skimage.transform import resize\n",
    "import imageio\n",
    "from scipy import stats\n",
    "# import seaborn as sns\n",
    "# import matplotlib.gridspec as gridspec\n",
    "# import matplotlib.patches as mpatches\n",
    "# import matplotlib.animation as anim\n",
    "# from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "# import h5py\n",
    "# import nilearn.plotting as nlplt\n",
    "# import nilearn as nl\n",
    "import pydicom as pdm\n",
    "import nibabel as nib\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# from scipy import stats\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import time\n",
    "import os\n",
    "# from tqdm import tqdm\n",
    "import torch\n",
    "# import torchvision.transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
    "from util.diceloss import DiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 43, 42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from tkinter.messagebox import NO\n",
    "from util.ccdataset3d import *\n",
    "train_path, valid_path, test_path = getPathList()\n",
    "train_loader = getDataloader_only1(\n",
    "    train_path,valid_paths=None,test_paths=None, B1=1)\n",
    "_,valid_loader,test_loader = getDataloader(\n",
    "    train_path, valid_path, test_path,B1=1\n",
    ")\n",
    "len(train_loader),len(valid_loader),len(test_loader)\n",
    "#(1,1,160,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "KernelSize = 3\n",
    "KernelSizePad = 1\n",
    "SamePadding = 2\n",
    "Stride = 2\n",
    "lr = 0.00001\n",
    "\n",
    "\n",
    "class Double_conv(nn.Module):\n",
    "    #conv->bn->relu->conv->bn->relu\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(16,out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(16,out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=Stride),\n",
    "            Double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_ch,in_ch,kernel_size=2,stride=2)\n",
    "        self.upcv = nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv = Double_conv(in_ch, out_ch)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.upcv(x1)\n",
    "        # diffZ = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        # diffY = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "        # diffX = torch.tensor([x2.size()[4] - x1.size()[4]])\n",
    "        # x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "        #                 diffY // 2, diffY - diffY // 2,\n",
    "        #                 diffZ // 2, diffZ - diffZ // 2, ])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)  # (B,C,D,H,W)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class compVnet(nn.Module):\n",
    "    def __init__(self, bilinear=True):\n",
    "        super(compVnet, self).__init__()\n",
    "        self.bilinear = bilinear\n",
    "        self.inc = Double_conv(1, 16)\n",
    "        self.down1 = Down(16, 32)\n",
    "        self.down2 = Down(32, 64)\n",
    "        self.down3 = Down(64, 128)\n",
    "        self.down4 = Down(128, 256)\n",
    "        self.up1 = Up(256, 128)\n",
    "        self.up2 = Up(128, 64)\n",
    "        self.up3 = Up(64, 32)\n",
    "        self.up4 = Up(32, 16)\n",
    "        self.outc = OutConv(16, 1)\n",
    "        self.up1x = Up(256, 128)\n",
    "        self.up2x = Up(128, 64)\n",
    "        self.up3x = Up(64, 32)\n",
    "        self.up4x = Up(32, 16)\n",
    "        self.outcx = OutConv(16, 1)\n",
    "        self.incz = Double_conv(1, 16)\n",
    "        self.down1z = Down(16, 32)\n",
    "        self.down2z = Down(32, 64)\n",
    "        self.down3z = Down(64,128)\n",
    "        self.down4z = Down(128, 256)\n",
    "        self.up1z = Up(256, 128)\n",
    "        self.up2z = Up(128, 64)\n",
    "        self.up3z = Up(64, 32)\n",
    "        self.up4z = Up(32, 16)\n",
    "        self.outcz = OutConv(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        y = self.up1x(x5, x4)\n",
    "        y = self.up2x(y, x3)\n",
    "        y = self.up3x(y, x2)\n",
    "        y = self.up4x(y, x1)\n",
    "        y = self.outcx(y)\n",
    "        # z = torch.cat([x, y], dim=1)\n",
    "        z = torch.sigmoid(x)+torch.sigmoid(y)\n",
    "        z1 = self.incz(z)\n",
    "        z2 = self.down1z(z1)\n",
    "        z3 = self.down2z(z2)\n",
    "        z4 = self.down3z(z3)\n",
    "        z5 = self.down4z(z4)\n",
    "        z = self.up1z(z5, z4)\n",
    "        z = self.up2z(z, z3)\n",
    "        z = self.up3z(z, z2)\n",
    "        z = self.up4z(z, z1)\n",
    "        z = self.outcz(z)\n",
    "\n",
    "        return x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KernelSize = 3\n",
    "Pool_stride = 2\n",
    "\n",
    "class Double_conv(nn.Module):\n",
    "    #conv->bn->relu->conv->bn->relu\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Double_conv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(32,out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=KernelSize, padding=1),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            # nn.GroupNorm(32, out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Down, self).__init__()\n",
    "        self.maxpool = nn.Sequential(\n",
    "            nn.MaxPool3d(kernel_size=2, stride=Pool_stride),\n",
    "            Double_conv(in_ch, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose3d(in_ch, in_ch, kernel_size=2, stride=2)\n",
    "        self.upcv = nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv = Double_conv(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x1 = self.upcv(x1)\n",
    "        # diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        # diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        # x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "        #                 diffY // 2, diffY - diffY // 2])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)  # (B,C,H,W)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.inc = Double_conv(1, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.down4 = Down(256, 512)\n",
    "        self.up1 = Up(512, 256)\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up3 = Up(128, 64)\n",
    "        self.up4 = Up(64, 32)\n",
    "        self.outc = OutConv(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        x = self.outc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全局权重初始化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('conv3d') != -1:\n",
    "        nn.init.kaiming_normal(m.weight)\n",
    "        m.bias.data.zero()\n",
    "\n",
    "#设置随机种子\n",
    "\n",
    "\n",
    "def seed_everthing(seed: int):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def training(epochs, model, trainLoader, validLoader):\n",
    "    # torch.cuda.set_device(0)\n",
    "    dice_list = []\n",
    "    seed_everthing(0)  # 设置全局随机种子\n",
    "    lr = 1e-4\n",
    "    dice_score = 0.\n",
    "    iou_score = 0.\n",
    "    writer = SummaryWriter('/data/zhanghao/skull_project/mae-main/base_line/3dUnet_cc_only1')\n",
    "    step = 0\n",
    "    weights_init(model)  # 模型权重初始化\n",
    "    Loss = DiceLoss()  # 实例化DiceLoss\n",
    "    model.train()  # 设置model为训练模式\n",
    "\n",
    "#____________________________________训练______________________________________________\n",
    "    for epoch in range(epochs):\n",
    "        # batch_num = 0  # 批次数\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)  # 每个epoch设置一次优化器\n",
    "        model.train()  # 设置为训练模式\n",
    "        optimizer.zero_grad()#优化器清零\n",
    "        for data in trainLoader:  \n",
    "\n",
    "            image = data[\"image\"]  \n",
    "            target = data[\"mask\"]\n",
    "\n",
    "            image = image.to(f'cuda:{model.device_ids[1,2,0]}')\n",
    "            target = target.to(f'cuda:{model.device_ids[1,2,0]}')\n",
    "\n",
    "            out1, out2, outx = model(image)\n",
    "            loss1 = Loss(out1, target)\n",
    "            loss2 = -Loss(out2, target)\n",
    "            lossx = F.mse_loss(outx, image)\n",
    "            loss = loss1+loss2+lossx\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(\"step=\",step)\n",
    "            writer.add_scalar(tag=\"loss1\", scalar_value=loss1, global_step=step)\n",
    "            writer.add_scalar(tag=\"loss2\", scalar_value=loss2, global_step=step)\n",
    "            writer.add_scalar(tag=\"lossx\", scalar_value=lossx, global_step=step)\n",
    "            writer.add_scalar(tag=\"loss\", scalar_value=loss, global_step=step)\n",
    "\n",
    "            # print(\"step=\",step)\n",
    "\n",
    "            writer.add_scalar(tag=\"loss\", scalar_value=loss, global_step=step)\n",
    "            step += 1\n",
    "        print(\"loss=\", loss)\n",
    "\n",
    "        optimizer.zero_grad()#在每轮训练后清零，给验证留出空间\n",
    "\n",
    "# ___________________________________验证_______________________________________________\n",
    "        #每4个epoch进行一次验证\n",
    "        if (epoch%4) == 0:\n",
    "            with torch.no_grad():  # 表示在验证的时候不需要进行梯度计算\n",
    "                model.eval()  # 设置model为验证模式\n",
    "                dice_score = 0.\n",
    "                iou_score = 0.\n",
    "                for data in validLoader:  # validLoader共60个nii文件,batch_size=1\n",
    "                    valid_image = data[\"image\"]  \n",
    "                    valid_target = data[\"mask\"]\n",
    "\n",
    "                    valid_image = valid_image.cuda(2)\n",
    "                    valid_target = valid_target.cuda(2)\n",
    "                    _, out, _ = model(valid_image)\n",
    "                    dice_score += dice_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                    iou_score += jaccard_coef_metric(out.cpu(), valid_target.cpu())\n",
    "                    \n",
    "                dice_score /= len(valid_loader)  # 算出平均dice_score\n",
    "                iou_score /= len(valid_loader)\n",
    "\n",
    "\n",
    "                print(\"epoch=\", epoch,\n",
    "                    \"dice_score=\", dice_score,\n",
    "                    \"iou_score=\", iou_score)\n",
    "\n",
    "                print(\"------------------------------------------------------------------\")\n",
    "                writer.add_scalar(tag=\"dice_scalar\", scalar_value=dice_score, global_step=epoch)\n",
    "                writer.add_scalar(tag=\"iou_scalar\", scalar_value=iou_score, global_step=epoch)\n",
    "                torch.save(model.state_dict(), '/data2/zhanghao/mae_project/3d_cc_only1/' +\n",
    "                                    str(epoch) + 'Vnet' + str(dice_score) + '.pth')\n",
    "\n",
    "        \n",
    "            #早停\n",
    "            if epoch > 20:\n",
    "                min = 999\n",
    "                for i in range(int(epoch/4 - 5) , int(epoch/4 - 1) ):\n",
    "                    if dice_list[i] < min:\n",
    "                        min = dice_list[i]\n",
    "                if dice_score < min:\n",
    "                    lr /= 10\n",
    "                    print(lr)\n",
    "                    if lr < 1e-6:\n",
    "                        break\n",
    "\n",
    "            dice_list.append(dice_score)#依次放入epoch为0 4 8 12 16 20 24....\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "print(\"len(train_loader)=\", len(train_loader), \"len(valid_loader)=\", len(valid_loader))\n",
    "model = compVnet()\n",
    "model = nn.DataParallel(model,device_ids=[1,2,0]) \n",
    "model.to(f'cuda:{model.device_ids[1,2,0]}')\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "training(epochs=600, model=model, trainLoader=train_loader, validLoader=valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 29, 56)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util.ccdataset3d import *\n",
    "train_paths, valid_paths, test_paths = getPathList()\n",
    "train_loader, valid_loader, test_loader = getDataloader(\n",
    "    train_paths, valid_paths, test_paths)\n",
    "len(train_loader),len(valid_loader),len(test_loader)\n",
    "# torch.Size([1, 1,160, 224, 224]) torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()\n",
    "model.load_state_dict(torch.load('/data/zhanghao/skull_project/mae-main/base_line/3dUnet_oasis_alldata/184Vnet0.9873532482555935.pth'))\n",
    "model = model.cuda(2)\n",
    "\n",
    "\n",
    "with torch.no_grad(): #表示在验证的时候不需要梯度计算\n",
    "    a = torch.ones([1,1,160,224,224]).cuda(2)\n",
    "    x = model(a)\n",
    "    x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73127884 0.5763905\n",
      "0.9260733 0.86232454\n",
      "0.75344473 0.60442144\n",
      "0.9262328 0.86260116\n",
      "0.4180332 0.26424906\n",
      "0.62848973 0.45824647\n",
      "0.7115481 0.5522504\n",
      "0.46707562 0.3046958\n",
      "0.6546576 0.48661038\n",
      "0.93505716 0.87803507\n",
      "0.93083507 0.8706188\n",
      "0.90488666 0.826295\n",
      "0.92883426 0.8671247\n",
      "0.75198483 0.6025446\n",
      "0.7897502 0.6525514\n",
      "0.8942437 0.80871683\n",
      "0.90844536 0.8322491\n",
      "0.84463584 0.731056\n",
      "0.7221101 0.56508\n",
      "0.69257957 0.5297298\n",
      "0.8455498 0.73242646\n",
      "0.92161447 0.8546243\n",
      "0.64881396 0.48018107\n",
      "0.69514394 0.5327361\n",
      "0.5056458 0.3383708\n",
      "0.5187912 0.35024852\n",
      "0.55211073 0.3813211\n",
      "0.86450446 0.7613455\n",
      "0.94506985 0.89586014\n",
      "0.91100216 0.83655095\n",
      "0.8717171 0.77260506\n",
      "0.7397221 0.58695155\n",
      "0.6742994 0.5086363\n",
      "0.93635124 0.88031995\n",
      "0.93752784 0.88240224\n",
      "0.9407002 0.8880396\n",
      "0.65820736 0.49054328\n",
      "0.807174 0.6766905\n",
      "0.6068669 0.43561298\n",
      "0.93081623 0.87058586\n",
      "0.94196653 0.8902994\n",
      "0.59832793 0.42686728\n",
      "0.8311215 0.71104187\n",
      "0.8511786 0.7409146\n",
      "9.387344e-16 9.387344e-16\n",
      "0.7299204 0.5747044\n",
      "0.92017126 0.8521456\n",
      "0.8828873 0.79032964\n",
      "0.93513465 0.87817174\n",
      "0.8129915 0.6849079\n",
      "0.93170106 0.8721351\n",
      "0.54951215 0.37884644\n",
      "6.5985735e-16 6.5985735e-16\n",
      "0.93333787 0.8750079\n",
      "0.83890533 0.7225124\n",
      "0.9171452 0.8469696\n",
      "mean_dice= 0.7626094062413488 mean_iou= 0.6524410215871674 std_dice= 0.20693326 std_iou= 0.22520347\n"
     ]
    }
   ],
   "source": [
    "m1_dice_list = []\n",
    "m1_iou_list = []\n",
    "with torch.no_grad(): #表示在验证的时候不需要梯度计算\n",
    "\n",
    "    model.eval()\n",
    "    dice_score = 0.\n",
    "    iou_score = 0.\n",
    "\n",
    "    for data in test_loader:\n",
    "        test_image = data[\"image\"].cuda(2)\n",
    "        test_target = data[\"mask\"].cuda(2)\n",
    "\n",
    "\n",
    "        out = model(test_image) \n",
    "        x = dice_coef_metric(out.cpu(), test_target.cpu())\n",
    "        y = jaccard_coef_metric(out.cpu(), test_target.cpu())\n",
    "        m1_dice_list.append(x)\n",
    "        m1_iou_list.append(y)\n",
    "        dice_score += x\n",
    "        iou_score += y\n",
    "        print(x, y)\n",
    "    \n",
    "    dice_score /= len(test_loader)\n",
    "    iou_score /= len(test_loader)\n",
    "    \n",
    "    print(\n",
    "        \"mean_dice=\", dice_score,\n",
    "        \"mean_iou=\", iou_score,\n",
    "        \"std_dice=\",np.std(m1_dice_list, ddof=1),\n",
    "        \"std_iou=\",np.std(m1_iou_list, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Warning] Fused window process have not been installed. Please refer to get_started.md for installation.\n"
     ]
    }
   ],
   "source": [
    "# Copyright (c) Meta Platforms, Inc. and affiliates.\n",
    "# All rights reserved.\n",
    "\n",
    "# This source code is licensed under the license found in the\n",
    "# LICENSE file in the root directory of this source tree.\n",
    "# --------------------------------------------------------\n",
    "# References:\n",
    "# DeiT: https://github.com/facebookresearch/deit\n",
    "# BEiT: https://github.com/microsoft/unilm/tree/master/beit\n",
    "# --------------------------------------------------------\n",
    "\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import timm\n",
    "\n",
    "# assert timm.__version__ == \"0.3.2\" # version check\n",
    "from timm.models.layers import trunc_normal_\n",
    "from timm.data.mixup import Mixup\n",
    "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n",
    "\n",
    "import util.lr_decay as lrd\n",
    "import util.misc as misc\n",
    "from util.datasets import build_dataset\n",
    "from util.pos_embed import interpolate_pos_embed\n",
    "from util.misc import NativeScalerWithGradNormCount as NativeScaler\n",
    "\n",
    "import models_vit\n",
    "\n",
    "from engine_finetune import train_one_epoch, evaluate\n",
    "from ast import arg\n",
    "import my_seg_vit\n",
    "import util.lr_sched as lr_sched\n",
    "import math\n",
    "import sys\n",
    "from my_metric import dice_coef_metric,jaccard_coef_metric\n",
    "import seg3d_2dencoder \n",
    "import maeseg2d3d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from email.policy import strict\n",
    "\n",
    "\n",
    "encoder_str='mae_vit_medical_half_patch16'\n",
    "# encoder_path='/data/zhanghao/skull_project/mae-main/pretrain_model/oasis_cc359_half_pretrain_out/checkpoint-399.pth'\n",
    "encoder = seg3d_2dencoder.__dict__[encoder_str](lossforpatch = True)\n",
    "# encoder.load_state_dict(torch.load(encoder_path),strict=False)\n",
    "model_str='mae_vit3d_medical_768_512_extra_windowsize4'\n",
    "# model_path='/data/zhanghao/skull_project/mae-main/base_line/seg_768_512_win4_b6_3d_cc359_010data_half_norm/checkpoint-296.pth'\n",
    "model = maeseg2d3d.__dict__[model_str](encoder= encoder)\n",
    "# model.load_state_dict(torch.load(model_path)['model'])\n",
    "path = '/data/zhanghao/skull_project/mae-main/base_line/3d_cc359_010data_half_norm_800_extra_freeze5/260ViT0.9693019154459931.pth'\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.957 0.91754556\n",
      "0.97585857 0.9528553\n",
      "0.9706333 0.9429422\n",
      "0.967074 0.93624705\n",
      "0.97597593 0.9530791\n",
      "0.9749041 0.951037\n",
      "0.87564737 0.7788014\n",
      "0.9776052 0.9561915\n",
      "0.97144884 0.94448274\n",
      "0.97417325 0.94964695\n",
      "0.96714306 0.93637663\n",
      "0.9755366 0.95224154\n",
      "0.95660293 0.91681576\n",
      "0.9804682 0.96168476\n",
      "0.96876216 0.93941677\n",
      "0.978965 0.95879674\n",
      "0.96523035 0.9327973\n",
      "0.96806765 0.93811154\n",
      "0.97544897 0.9520745\n",
      "0.9648248 0.9320401\n",
      "0.96501064 0.93238705\n",
      "0.9711234 0.9438677\n",
      "0.9644741 0.9313857\n",
      "0.94793075 0.9010156\n",
      "0.9689322 0.9397367\n",
      "0.9734569 0.9482864\n",
      "0.9572758 0.9180527\n",
      "0.9651229 0.9325966\n",
      "0.9774281 0.9558526\n",
      "0.9696873 0.94115824\n",
      "0.9720174 0.94555825\n",
      "0.97094434 0.94352955\n",
      "0.9789587 0.9587847\n",
      "0.9589038 0.92105204\n",
      "0.9709563 0.94355214\n",
      "0.9514971 0.90748155\n",
      "0.96293795 0.9285249\n",
      "0.9701751 0.9420777\n",
      "0.9694127 0.940641\n",
      "0.975069 0.95135087\n",
      "0.96499664 0.9323608\n",
      "0.96936566 0.9405525\n",
      "mean_dice= 0.9665963578791845 mean_iou= 0.9357854695547194 std_dice= 0.016161382 std_iou= 0.028397165\n"
     ]
    }
   ],
   "source": [
    "m2_dice_list = []\n",
    "m2_iou_list = []\n",
    "with torch.no_grad(): #表示在验证的时候不需要梯度计算\n",
    "\n",
    "    model.eval()\n",
    "    dice_score = 0.\n",
    "    iou_score = 0.\n",
    "\n",
    "    for data in test_loader:\n",
    "        test_image = data[\"image\"]\n",
    "        test_target = data[\"mask\"]\n",
    "\n",
    "        test_image = test_image.to('cuda:2', non_blocking=True)\n",
    "        test_target = test_target.to('cuda:2', non_blocking=True)\n",
    "\n",
    "        _,out = model(test_image, test_target) #[N,196,256]\n",
    "        out = model.unpatchify3D(out) #[N,1,224,224]\n",
    "\n",
    "        \n",
    "        x = dice_coef_metric(out.cpu(), test_target.cpu())\n",
    "        y = jaccard_coef_metric(out.cpu(), test_target.cpu())\n",
    "        m2_dice_list.append(x)\n",
    "        m2_iou_list.append(y)\n",
    "        dice_score += x\n",
    "        iou_score += y\n",
    "        print(x, y)\n",
    "    \n",
    "    dice_score /= len(test_loader)\n",
    "    iou_score /= len(test_loader)\n",
    "    \n",
    "    print(\n",
    "        \"mean_dice=\", dice_score,\n",
    "        \"mean_iou=\", iou_score,\n",
    "        \"std_dice=\",np.std(m2_dice_list, ddof=1),\n",
    "        \"std_iou=\",np.std(m2_iou_list, ddof=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Ttest_indResult(statistic=-0.29834338855925147, pvalue=0.7661957793870071),\n",
       " Ttest_indResult(statistic=-0.040624969820090666, pvalue=0.9676936290528062))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "stats.ttest_ind(m1_dice_list, m2_dice_list),stats.ttest_ind(m1_iou_list, m2_iou_list),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('ZH': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
