{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(img_list='/data2/zhanghao/p.txt',\n",
      "img_prefix=None,\n",
      "img_suffix=None,\n",
      "atlas=None,\n",
      "model_dir='/data2/zhanghao/mae_project/voxelmorph_model/',\n",
      "multichannel=False,\n",
      "gpu='1',\n",
      "batch_size=3,\n",
      "epochs=500,\n",
      "steps_per_epoch=138,\n",
      "load_model='/data2/zhanghao/mae_project/voxelmorph_model/0080.pt',\n",
      "initial_epoch=80,\n",
      "lr=0.0001,\n",
      "cudnn_nondet=False,\n",
      "enc=None,\n",
      "dec=None,\n",
      "int_steps=7,\n",
      "int_downsize=1,\n",
      "bidir=False,\n",
      "image_loss='mse',\n",
      "weight=0.01,\n",
      "log_dir='/data/zhanghao/skull_project/mae-main/register_out/output_log')\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"\n",
    "Example script to train a VoxelMorph model.\n",
    "\n",
    "You will likely have to customize this script slightly to accommodate your own data. All images\n",
    "should be appropriately cropped and scaled to values between 0 and 1.\n",
    "\n",
    "If an atlas file is provided with the --atlas flag, then scan-to-atlas training is performed.\n",
    "Otherwise, registration will be scan-to-scan.\n",
    "\n",
    "If you use this code, please cite the following, and read function docs for further info/citations.\n",
    "\n",
    "    VoxelMorph: A Learning Framework for Deformable Medical Image Registration G. Balakrishnan, A.\n",
    "    Zhao, M. R. Sabuncu, J. Guttag, A.V. Dalca. IEEE TMI: Transactions on Medical Imaging. 38(8). pp\n",
    "    1788-1800. 2019. \n",
    "\n",
    "    or\n",
    "\n",
    "    Unsupervised Learning for Probabilistic Diffeomorphic Registration for Images and Surfaces\n",
    "    A.V. Dalca, G. Balakrishnan, J. Guttag, M.R. Sabuncu. \n",
    "    MedIA: Medical Image Analysis. (57). pp 226-236, 2019 \n",
    "\n",
    "Copyright 2020 Adrian V. Dalca\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in\n",
    "compliance with the License. You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is\n",
    "distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "implied. See the License for the specific language governing permissions and limitations under the\n",
    "License.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# import voxelmorph with pytorch backend\n",
    "os.environ['VXM_BACKEND'] = 'pytorch'\n",
    "import voxelmorph as vxm  # nopep8\n",
    "\n",
    "# parse the commandline\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# data organization parameters\n",
    "parser.add_argument('--img-list',default=\"/data2/zhanghao/p.txt\", help='line-seperated list of training files')\n",
    "parser.add_argument('--img-prefix', help='optional input image file prefix')\n",
    "parser.add_argument('--img-suffix', help='optional input image file suffix')\n",
    "parser.add_argument('--atlas', help='atlas filename (default: data/atlas_norm.npz)')\n",
    "parser.add_argument('--model-dir', default='/data2/zhanghao/mae_project/voxelmorph_model/',\n",
    "                    help='model output directory (default: models)')\n",
    "parser.add_argument('--multichannel', action='store_true',\n",
    "                    help='specify that data has multiple channels')\n",
    "\n",
    "# training parameters\n",
    "parser.add_argument('--gpu', default='1', help='GPU ID number(s), comma-separated (default: 0)')\n",
    "parser.add_argument('--batch-size', type=int, default=3, help='batch size (default: 1)')\n",
    "parser.add_argument('--epochs', type=int, default=500,\n",
    "                    help='number of training epochs (default: 1500)')\n",
    "parser.add_argument('--steps-per-epoch', type=int, default=138,\n",
    "                    help='frequency of model saves (default: 100)')\n",
    "parser.add_argument('--load-model', default='/data2/zhanghao/mae_project/voxelmorph_model/0080.pt',help='optional model file to initialize with')\n",
    "parser.add_argument('--initial-epoch', type=int, default=80,\n",
    "                    help='initial epoch number (default: 0)')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, help='learning rate (default: 1e-4)')\n",
    "parser.add_argument('--cudnn-nondet', action='store_true',\n",
    "                    help='disable cudnn determinism - might slow down training')\n",
    "\n",
    "# network architecture parameters\n",
    "parser.add_argument('--enc', type=int, nargs='+',\n",
    "                    help='list of unet encoder filters (default: 16 32 32 32)')\n",
    "parser.add_argument('--dec', type=int, nargs='+',\n",
    "                    help='list of unet decorder filters (default: 32 32 32 32 32 16 16)')\n",
    "parser.add_argument('--int-steps', type=int, default=7,\n",
    "                    help='number of integration steps (default: 7)')\n",
    "parser.add_argument('--int-downsize', type=int, default=1,\n",
    "                    help='flow downsample factor for integration (default: 2)')\n",
    "parser.add_argument('--bidir', action='store_true', help='enable bidirectional cost function')\n",
    "\n",
    "# loss hyperparameters\n",
    "parser.add_argument('--image-loss', default='mse',\n",
    "                    help='image reconstruction loss - can be mse or ncc (default: mse)')\n",
    "parser.add_argument('--lambda', type=float, dest='weight', default=0.01,\n",
    "                    help='weight of deformation loss (default: 0.01)')\n",
    "parser.add_argument('--log_dir', default='/data/zhanghao/skull_project/mae-main/register_out/output_log',\n",
    "                    help='path where to tensorboard log')\n",
    "\n",
    "args = parser.parse_args(args = [])\n",
    "print(\"{}\".format(args).replace(', ', ',\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def new_list():\n",
    "    oa_path = '/data2/zhanghao/oasis4_35/train_npy/'\n",
    "    ad_path = '/data2/zhanghao/adni/train_npy/train_data/'\n",
    "    paths = []\n",
    "    little_paths = []\n",
    "\n",
    "    for j in os.listdir(ad_path):\n",
    "        string = os.path.join(ad_path,j)+'\\n'\n",
    "        little_paths.append(string)\n",
    "    random.shuffle(little_paths)\n",
    "\n",
    "    paths = little_paths[:414]\n",
    "\n",
    "    for i in os.listdir(oa_path):\n",
    "        string = os.path.join(oa_path,i)+'\\n'\n",
    "        paths.append(string)\n",
    "    random.shuffle(paths)\n",
    "    with open(\"/data2/zhanghao/p.txt\", 'w') as f:\n",
    "        for i in range(len(paths)):\n",
    "            f.write(paths[i])\n",
    "    path = '/data2/zhanghao/p.txt'\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data56.npy\n",
      "load model at ...\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data299.npy\n",
      "Epoch 81/500 - 3.6346 sec/step - loss: 3.3497e-03  (2.2919e-03, 1.0578e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data737.npy\n",
      "Epoch 82/500 - 3.7942 sec/step - loss: 3.4991e-03  (2.4361e-03, 1.0630e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data1348.npy\n",
      "Epoch 83/500 - 3.6137 sec/step - loss: 3.4548e-03  (2.3899e-03, 1.0649e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data19.npy\n",
      "Epoch 84/500 - 3.8433 sec/step - loss: 3.2278e-03  (2.1995e-03, 1.0284e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data363.npy\n",
      "Epoch 85/500 - 3.7733 sec/step - loss: 3.5113e-03  (2.4335e-03, 1.0778e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data378.npy\n",
      "Epoch 86/500 - 3.7386 sec/step - loss: 3.7316e-03  (2.6301e-03, 1.1015e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data300.npy\n",
      "Epoch 87/500 - 3.4672 sec/step - loss: 2.9872e-03  (1.9795e-03, 1.0077e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data386.npy\n",
      "Epoch 88/500 - 3.4977 sec/step - loss: 3.6145e-03  (2.5005e-03, 1.1140e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data120.npy\n",
      "Epoch 89/500 - 3.6194 sec/step - loss: 3.6160e-03  (2.5454e-03, 1.0706e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data62.npy\n",
      "Epoch 90/500 - 3.5663 sec/step - loss: 3.3375e-03  (2.2447e-03, 1.0929e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data410.npy\n",
      "Epoch 91/500 - 3.5204 sec/step - loss: 3.3478e-03  (2.3086e-03, 1.0392e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data123.npy\n",
      "Epoch 92/500 - 3.5187 sec/step - loss: 3.1822e-03  (2.1398e-03, 1.0424e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data284.npy\n",
      "Epoch 93/500 - 3.4827 sec/step - loss: 3.4985e-03  (2.4020e-03, 1.0964e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data997.npy\n",
      "Epoch 94/500 - 3.6040 sec/step - loss: 3.5880e-03  (2.5202e-03, 1.0678e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data896.npy\n",
      "Epoch 95/500 - 3.6792 sec/step - loss: 3.7072e-03  (2.6322e-03, 1.0751e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data252.npy\n",
      "Epoch 96/500 - 3.9013 sec/step - loss: 3.5742e-03  (2.4932e-03, 1.0810e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data3.npy\n",
      "Epoch 97/500 - 4.0778 sec/step - loss: 3.3152e-03  (2.2601e-03, 1.0552e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data797.npy\n",
      "Epoch 98/500 - 3.8830 sec/step - loss: 3.3457e-03  (2.2636e-03, 1.0821e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data1043.npy\n",
      "Epoch 99/500 - 3.7360 sec/step - loss: 3.4357e-03  (2.4168e-03, 1.0188e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data35.npy\n",
      "Epoch 100/500 - 3.7136 sec/step - loss: 3.9197e-03  (2.7840e-03, 1.1357e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data110.npy\n",
      "Epoch 101/500 - 3.6754 sec/step - loss: 3.5300e-03  (2.4325e-03, 1.0975e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data923.npy\n",
      "Epoch 102/500 - 3.6136 sec/step - loss: 3.9050e-03  (2.7721e-03, 1.1329e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data1171.npy\n",
      "Epoch 103/500 - 3.6140 sec/step - loss: 3.5825e-03  (2.5043e-03, 1.0781e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data5.npy\n",
      "Epoch 104/500 - 3.7584 sec/step - loss: 3.5248e-03  (2.4241e-03, 1.1007e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data185.npy\n",
      "Epoch 105/500 - 3.8978 sec/step - loss: 3.7624e-03  (2.6208e-03, 1.1416e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data217.npy\n",
      "Epoch 106/500 - 3.8653 sec/step - loss: 3.3797e-03  (2.3131e-03, 1.0666e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/adni/train_npy/train_data/train_data715.npy\n",
      "Epoch 107/500 - 3.6228 sec/step - loss: 3.4373e-03  (2.3780e-03, 1.0594e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data46.npy\n",
      "Epoch 108/500 - 3.6885 sec/step - loss: 3.2387e-03  (2.1785e-03, 1.0603e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data373.npy\n",
      "Epoch 109/500 - 3.6936 sec/step - loss: 3.5093e-03  (2.4316e-03, 1.0776e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data171.npy\n",
      "Epoch 110/500 - 3.5949 sec/step - loss: 3.3289e-03  (2.2538e-03, 1.0751e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data126.npy\n",
      "Epoch 111/500 - 3.6074 sec/step - loss: 3.7613e-03  (2.6552e-03, 1.1061e-03)\n",
      "log_dir: /data/zhanghao/skull_project/mae-main/register_out/output_log\n",
      "len_train_files=  828   first_train_files=  /data2/zhanghao/oasis4_35/train_npy/train_data306.npy\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "log_writer = SummaryWriter(log_dir=args.log_dir)\n",
    "bidir = args.bidir\n",
    "\n",
    "# load and prepare training data\n",
    "train_files = vxm.py.utils.read_file_list(args.img_list, prefix=args.img_prefix,\n",
    "                                          suffix=args.img_suffix)\n",
    "assert len(train_files) > 0, 'Could not find any training data.'\n",
    "print('len_train_files= ',len(train_files),'  first_train_files= ',train_files[0])\n",
    "\n",
    "# no need to append an extra feature axis if data is multichannel\n",
    "add_feat_axis = not args.multichannel\n",
    "\n",
    "if args.atlas:\n",
    "    # scan-to-atlas generator\n",
    "    atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol',\n",
    "                                      add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "    generator = vxm.generators.scan_to_atlas(train_files, atlas,\n",
    "                                             batch_size=args.batch_size, bidir=args.bidir,\n",
    "                                             add_feat_axis=add_feat_axis)\n",
    "else:\n",
    "    # scan-to-scan generator\n",
    "    generator = vxm.generators.scan_to_scan(\n",
    "        train_files, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "# extract shape from sampled input\n",
    "inshape = next(generator)[0][0].shape[1:-1]\n",
    "\n",
    "# prepare model folder\n",
    "model_dir = args.model_dir\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# device handling\n",
    "gpus = args.gpu.split(',')\n",
    "nb_gpus = len(gpus)\n",
    "device = 'cuda'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "assert np.mod(args.batch_size, nb_gpus) == 0, \\\n",
    "    'Batch size (%d) should be a multiple of the nr of gpus (%d)' % (args.batch_size, nb_gpus)\n",
    "\n",
    "# enabling cudnn determinism appears to speed up training by a lot\n",
    "torch.backends.cudnn.deterministic = not args.cudnn_nondet\n",
    "\n",
    "# unet architecture\n",
    "enc_nf = args.enc if args.enc else [16, 32, 32, 32]\n",
    "dec_nf = args.dec if args.dec else [32, 32, 32, 32, 32, 16, 16]\n",
    "\n",
    "if args.load_model:\n",
    "    # load initial model (if specified)\n",
    "    model = vxm.networks.VxmDense.load(args.load_model, device)\n",
    "    print('load model at ...')\n",
    "else:\n",
    "    # otherwise configure new model\n",
    "    model = vxm.networks.VxmDense(\n",
    "        inshape=inshape,\n",
    "        nb_unet_features=[enc_nf, dec_nf],\n",
    "        bidir=bidir,\n",
    "        int_steps=args.int_steps,\n",
    "        int_downsize=args.int_downsize\n",
    "    )\n",
    "\n",
    "if nb_gpus > 1:\n",
    "    # use multiple GPUs via DataParallel\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    model.save = model.module.save\n",
    "\n",
    "# prepare the model for training and send to device\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "# set optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "# prepare image loss\n",
    "if args.image_loss == 'ncc':\n",
    "    image_loss_func = vxm.losses.NCC().loss\n",
    "elif args.image_loss == 'mse':\n",
    "    image_loss_func = vxm.losses.MSE().loss\n",
    "else:\n",
    "    raise ValueError('Image loss should be \"mse\" or \"ncc\", but found \"%s\"' % args.image_loss)\n",
    "\n",
    "# need two image loss functions if bidirectional\n",
    "if bidir:\n",
    "    losses = [image_loss_func, image_loss_func]\n",
    "    weights = [0.5, 0.5]\n",
    "else:\n",
    "    losses = [image_loss_func]\n",
    "    weights = [1]\n",
    "\n",
    "# prepare deformation loss\n",
    "losses += [vxm.losses.Grad('l2', loss_mult=args.int_downsize).loss]\n",
    "weights += [args.weight]\n",
    "\n",
    "# training loops\n",
    "for epoch in range(args.initial_epoch, args.epochs):\n",
    "    if log_writer is not None:\n",
    "        print('log_dir: {}'.format(log_writer.log_dir))\n",
    "    #每个epoch生成一个train_file\n",
    "    # load and prepare training data\n",
    "    img_list = new_list()\n",
    "    train_files = vxm.py.utils.read_file_list(img_list, prefix=args.img_prefix,\n",
    "                                            suffix=args.img_suffix)\n",
    "    assert len(train_files) > 0, 'Could not find any training data.'\n",
    "    print('len_train_files= ',len(train_files),'  first_train_files= ',train_files[0])\n",
    "\n",
    "    # no need to append an extra feature axis if data is multichannel\n",
    "    add_feat_axis = not args.multichannel\n",
    "\n",
    "    if args.atlas:\n",
    "        # scan-to-atlas generator\n",
    "        atlas = vxm.py.utils.load_volfile(args.atlas, np_var='vol',\n",
    "                                        add_batch_axis=True, add_feat_axis=add_feat_axis)\n",
    "        generator = vxm.generators.scan_to_atlas(train_files, atlas,\n",
    "                                                batch_size=args.batch_size, bidir=args.bidir,\n",
    "                                                add_feat_axis=add_feat_axis)\n",
    "    else:\n",
    "        # scan-to-scan generator\n",
    "        generator = vxm.generators.scan_to_scan(\n",
    "            train_files, batch_size=args.batch_size, bidir=args.bidir, add_feat_axis=add_feat_axis)\n",
    "\n",
    "    # save model checkpoint\n",
    "    if epoch % 20 == 0:\n",
    "        model.save(os.path.join(model_dir, '%04d.pt' % epoch))\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_total_loss = []\n",
    "    epoch_step_time = []\n",
    "\n",
    "    for step in range(args.steps_per_epoch):\n",
    "        # print(step)\n",
    "\n",
    "        step_start_time = time.time()\n",
    "\n",
    "        # generate inputs (and true outputs) and convert them to tensors\n",
    "        inputs, y_true = next(generator)\n",
    "        inputs = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in inputs]\n",
    "        y_true = [torch.from_numpy(d).to(device).float().permute(0, 4, 1, 2, 3) for d in y_true]\n",
    "\n",
    "        # run inputs through the model to produce a warped image and flow field\n",
    "        y_pred = model(*inputs)\n",
    "\n",
    "        # calculate total loss\n",
    "        loss = 0\n",
    "        loss_list = []\n",
    "        for n, loss_function in enumerate(losses):\n",
    "            curr_loss = loss_function(y_true[n], y_pred[n]) * weights[n]\n",
    "            loss_list.append(curr_loss.item())\n",
    "            loss += curr_loss\n",
    "\n",
    "        epoch_loss.append(loss_list)\n",
    "        epoch_total_loss.append(loss.item())\n",
    "\n",
    "        # backpropagate and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # get compute time\n",
    "        epoch_step_time.append(time.time() - step_start_time)\n",
    "\n",
    "    # print epoch info\n",
    "    epoch_info = 'Epoch %d/%d' % (epoch + 1, args.epochs)\n",
    "    time_info = '%.4f sec/step' % np.mean(epoch_step_time)\n",
    "    losses_info = ', '.join(['%.4e' % f for f in np.mean(epoch_loss, axis=0)])\n",
    "    loss_info = 'loss: %.4e  (%s)' % (np.mean(epoch_total_loss), losses_info)\n",
    "    print(' - '.join((epoch_info, time_info, loss_info)), flush=True)\n",
    "    log_writer.add_scalar('train_loss', loss, epoch)\n",
    "\n",
    "# final model save\n",
    "model.save(os.path.join(model_dir, '%04d.pt' % args.epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('ZH')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d66a6644cd8b9bdcc5b69d4f758b89eb8a6590d2d16af97b0232df0dbc0ae54"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
